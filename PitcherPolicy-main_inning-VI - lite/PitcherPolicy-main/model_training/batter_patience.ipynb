{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batter Patience Model: data cleaning, model training, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import appropriate libraries\n",
    "import pandas, json, requests, urllib, io\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras        \n",
    "import numpy as np        \n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models, layers, Input, optimizers, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitsu\\AppData\\Local\\Temp\\ipykernel_5368\\2575261644.py:5: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  pitchData = pandas.read_csv(\"all_pitch.csv\", error_bad_lines=False)\n"
     ]
    }
   ],
   "source": [
    "# Gets the pitch data csv from local file\n",
    "def get_total_pitch_data():\n",
    "\n",
    "  \n",
    "  pitchData = pandas.read_csv(\"all_pitch.csv\", error_bad_lines=False)\n",
    "  pitchData = pitchData.rename({\"res\":\"result\"}, axis = 1)\n",
    "  del pitchData[\"zone\"]\n",
    "  pitchData[\"zone\"] = pitchData['zones']\n",
    "  pitchData[\"zones\"] = pitchData['zones'].map(lambda x: x.rstrip('aAbB')).astype(int)\n",
    "  \n",
    "  return pitchData\n",
    "\n",
    "\n",
    "total_pitch_data = get_total_pitch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a map from batter ID to batter tensor \n",
    "def get_batter_tensors(df_pitch):\n",
    "  batter_tensors = {}\n",
    "\n",
    "  pitch_types = [\"FF\", \"FT\", \"CU\", \"CH\", \"FC\", \"SL\"]\n",
    "  batters = df_pitch['batter_id'].unique()\n",
    "\n",
    "  zones = df_pitch['zones'].unique()\n",
    "  zones.sort()\n",
    "\n",
    "  for batter in batters: \n",
    "    batter_tensor = [0] * len(pitch_types)\n",
    "\n",
    "    df_batter = df_pitch.loc[df_pitch['batter_id'] == batter]\n",
    "    \n",
    "    for i, pitch in enumerate(pitch_types):\n",
    "      batter_tensor[i] = [0] * len(zones)\n",
    "\n",
    "      df_pitch_type = df_batter.loc[df_batter['pitch_type'] == pitch]\n",
    "      for zone in zones: \n",
    "        batter_tensor[i][zone] = [0] * 2\n",
    "\n",
    "        if df_pitch_type.shape[0] != 0: \n",
    "          df_pitch_type_zone = df_pitch_type.loc[df_pitch_type['zones'] == zone]\n",
    "          num_pitch_type_in_zone = df_pitch_type_zone.shape[0]\n",
    "\n",
    "          if num_pitch_type_in_zone != 0: \n",
    "            df_swing = df_pitch_type_zone.loc[df_pitch_type_zone['swing'] == 1]\n",
    "            num_swing = df_swing.shape[0]\n",
    "            proportion_swing = num_swing / num_pitch_type_in_zone\n",
    "\n",
    "            num_hit = df_swing.loc[df_swing['result'] == 'Hit'].shape[0]\n",
    "            proportion_hit = num_hit / num_pitch_type_in_zone\n",
    "\n",
    "            batter_tensor[i][zone][0] = proportion_swing\n",
    "            batter_tensor[i][zone][1] = proportion_hit\n",
    "    batter_tensors[batter] = batter_tensor\n",
    "  return batter_tensors\n",
    "\n",
    "batter_tensors = get_batter_tensors(total_pitch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshapes batter tensor from (6,17,2) to (5,5,12)\n",
    "def reshape_batter_tensors(batter_tensors):\n",
    "    new_batter_tensors = {}\n",
    "    zone_index_map = {\n",
    "        0:(1,1), #(x,y)\n",
    "        1:(2,1),\n",
    "        2:(3,1),\n",
    "        3:(1,2),\n",
    "        4:(2,2),\n",
    "        5:(3,2),\n",
    "        6:(1,3),\n",
    "        7:(2,3),\n",
    "        8:(3,3),\n",
    "        9:(0,0),\n",
    "        10:(np.s_[1:4],0),\n",
    "        11:(4,0),\n",
    "        12:(0,np.s_[1:4]),\n",
    "        13:(4,np.s_[1:4]),\n",
    "        14:(0,4),\n",
    "        15:(np.s_[1:4],4),\n",
    "        16:(4,4)\n",
    "    }\n",
    "\n",
    "    for batter_key in batter_tensors.keys():\n",
    "        batter = np.array(batter_tensors[batter_key])\n",
    "    \n",
    "        new_tensor = np.zeros((0,5,5))\n",
    "        for pitch in batter:\n",
    "            #print(pitch.shape)\n",
    "            zone_matrix = np.zeros((2,5,5))\n",
    "            \n",
    "            for i, zone in enumerate(pitch):\n",
    "                index = zone_index_map[i]\n",
    "                #print(index)\n",
    "                #print(index[0],index[1])\n",
    "                #print(zone[0],zone[1])\n",
    "                zone_matrix[0,index[1],index[0]]= zone[0]\n",
    "                zone_matrix[1,index[1],index[0]]= zone[1]\n",
    "            #print(zone_matrix.shape)\n",
    "            new_tensor = np.concatenate((new_tensor,zone_matrix),axis=0)\n",
    "            \n",
    "        new_tensor = new_tensor.reshape((5,5,12))\n",
    "        new_batter_tensors[batter_key]=new_tensor\n",
    "            \n",
    "        \n",
    "    \n",
    "    return new_batter_tensors\n",
    "\n",
    "batter_tensors = reshape_batter_tensors(batter_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters pitches to nonobvious outside zones\n",
    "def get_reduced_df(total_df):\n",
    "    return total_df[((total_df[\"zones\"]>=9) & (total_df[\"zone\"].str[-1]==\"a\"))]\n",
    "new_df = get_reduced_df(total_pitch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets (5,5,6) tensor representing the pitch loc x pitch type\n",
    "def get_pitch_tensor(zone, pitch_type):\n",
    "    pitch_types = [\"FF\", \"FT\", \"CU\", \"CH\", \"FC\", \"SL\"]\n",
    "    pitch_tensor = np.zeros((5,5,6))\n",
    "    p_ind = pitch_types.index(pitch_type)\n",
    "    zone_index_map = {\n",
    "        0:(1,1), #(x,y)\n",
    "        1:(2,1),\n",
    "        2:(3,1),\n",
    "        3:(1,2),\n",
    "        4:(2,2),\n",
    "        5:(3,2),\n",
    "        6:(1,3),\n",
    "        7:(2,3),\n",
    "        8:(3,3),\n",
    "        9:(0,0),\n",
    "        10:(np.s_[1:4],0),\n",
    "        11:(4,0),\n",
    "        12:(0,np.s_[1:4]),\n",
    "        13:(4,np.s_[1:4]),\n",
    "        14:(0,4),\n",
    "        15:(np.s_[1:4],4),\n",
    "        16:(4,4)\n",
    "    }\n",
    "    pitch_tensor[zone_index_map[zone][0],zone_index_map[zone][1], p_ind] = 1\n",
    "   \n",
    "    return pitch_tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterates through all pitches and creates lists of the batter, ids, outcome, strike count, ball count, pitch type\n",
    "def create_input_output_tensors( batter_tensors, pitches):\n",
    "\n",
    "\n",
    "\n",
    "  batter = []\n",
    "  outcome = []\n",
    "  s_count = []\n",
    "  b_count = []\n",
    "  ids = []\n",
    "  pitch = []\n",
    "\n",
    "  for i, row in pitches.iterrows():\n",
    "\n",
    "    if row.batter_id in batter_tensors.keys():\n",
    "       \n",
    "        batter.append(batter_tensors[row.batter_id])\n",
    "        ids.append((row.pitcher_id, row.batter_id, i))\n",
    "        outcome.append(row.swing)\n",
    "        s_count.append(row.s_count)\n",
    "        b_count.append(row.b_count)\n",
    "        pitch.append(get_pitch_tensor(row.zones,row.pitch_type))\n",
    "\n",
    "  data = {\n",
    "      'Batter' : batter,\n",
    "      'Outcome' : outcome,\n",
    "      'IDs' : ids,\n",
    "      's_count': s_count,\n",
    "      'b_count': b_count,\n",
    "      'Pitch': pitch\n",
    "      \n",
    "  }\n",
    "\n",
    "  return data\n",
    "\n",
    "input_output_tensors = create_input_output_tensors( batter_tensors, new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to np arrays \n",
    "batter_inputs = np.array(input_output_tensors['Batter'])\n",
    "outcome = np.array(input_output_tensors['Outcome'])\n",
    "s_count = np.array(input_output_tensors['s_count'])\n",
    "b_count = np.array(input_output_tensors['b_count'])\n",
    "ids = input_output_tensors['IDs']\n",
    "pitch_inputs = np.array(input_output_tensors['Pitch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate tensor lists\n",
    "input_output_tensors = {\n",
    "    'Batter' : batter_inputs,\n",
    "    'Outcome' : outcome,\n",
    "    'IDs' : ids,\n",
    "    's_count' : s_count,\n",
    "    'b_count' : b_count,\n",
    "    'Pitch' : pitch_inputs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of pitch indices for training, validation, and test\n",
    "def get_train_val_test_indices(swing_df):\n",
    "    train_val_test_indices = {\n",
    "        'train':[],\n",
    "        'validation':[],\n",
    "        'test':[]\n",
    "    }\n",
    "    row_count = 0\n",
    "    for i, row in swing_df.iterrows():\n",
    "      \n",
    "        \n",
    "            \n",
    "            if row_count< swing_df.shape[0]*.7:\n",
    "                train_val_test_indices[\"train\"].append(row_count)\n",
    "            elif row_count< swing_df.shape[0]*.85:\n",
    "  \n",
    "                train_val_test_indices[\"validation\"].append(row_count)\n",
    "            else:\n",
    "   \n",
    "                train_val_test_indices[\"test\"].append(row_count)\n",
    "\n",
    "            row_count += 1\n",
    "                \n",
    "            \n",
    "    \n",
    "    \n",
    "    return train_val_test_indices\n",
    "    \n",
    "train_val_test_indices = get_train_val_test_indices(new_df)\n",
    "\n",
    "train_indices = train_val_test_indices['train']\n",
    "val_indices = train_val_test_indices['validation']\n",
    "test_indices = train_val_test_indices['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j: 591307\n",
      "j: 718014\n"
     ]
    }
   ],
   "source": [
    "# Splits the data into the three sets based on the gotten indices\n",
    "def get_train_val_test_sets(train_indices, val_indices, test_indices, tensors):\n",
    "  b_train = []\n",
    "  b_test = []\n",
    "  b_val = []\n",
    "\n",
    "  o_train = []\n",
    "  o_test = []\n",
    "  o_val = []\n",
    "\n",
    "  ids_train = []\n",
    "  ids_val = []\n",
    "  ids_test = []\n",
    "    \n",
    "  sc_train = []\n",
    "  sc_val = []\n",
    "  sc_test = []\n",
    "\n",
    "  bc_train = []\n",
    "  bc_val = []\n",
    "  bc_test = []\n",
    "    \n",
    "  pitch_train = []\n",
    "  pitch_val = []\n",
    "  pitch_test = []\n",
    "\n",
    "  \n",
    "  for i in train_indices:\n",
    "    if i < len(tensors['Batter']):\n",
    "        b_train.append(tensors['Batter'][i])\n",
    "        o_train.append(tensors['Outcome'][i])\n",
    "        ids_train.append(tensors['IDs'][i])\n",
    "        sc_train.append(tensors['s_count'][i])\n",
    "        bc_train.append(tensors['b_count'][i])\n",
    "        pitch_train.append(tensors['Pitch'][i])\n",
    "  for j in val_indices:\n",
    "    if j == val_indices[0]: print(\"j: %s\" %j)\n",
    "    if j == val_indices[-1]: print(\"j: %s\" %j)\n",
    "    if j < len(tensors['Batter']):\n",
    "        b_val.append(tensors['Batter'][j])\n",
    "        o_val.append(tensors['Outcome'][j])\n",
    "        ids_val.append(tensors['IDs'][j])\n",
    "        sc_val.append(tensors['s_count'][j])\n",
    "        bc_val.append(tensors['b_count'][j])\n",
    "        pitch_val.append(tensors['Pitch'][j])\n",
    "  for k in test_indices:\n",
    "    if k == val_indices[0]: print(\"k: %s\" %j)\n",
    "    if k == val_indices[-1]: print(\"k: %s\" %j)\n",
    "    if k < len(tensors['Batter']):\n",
    "        b_test.append(tensors['Batter'][k])\n",
    "        o_test.append(tensors['Outcome'][k])\n",
    "        ids_test.append(tensors['IDs'][k])\n",
    "        sc_test.append(tensors['s_count'][k])\n",
    "        bc_test.append(tensors['b_count'][k])\n",
    "        pitch_test.append(tensors['Pitch'][k])\n",
    "  sets = {\n",
    "      'Training' : {\n",
    "          'Batter' : b_train,\n",
    "          'Outcome' : o_train,\n",
    "          'IDs' : ids_train,\n",
    "          's_count' : sc_train,\n",
    "          'b_count' : bc_train,\n",
    "          'Pitch' : pitch_train\n",
    "      },\n",
    "      'Validation' : {\n",
    "          'Batter' : b_val,\n",
    "          'Outcome' : o_val,\n",
    "          'IDs' : ids_val,\n",
    "          's_count' : sc_val,\n",
    "          'b_count' : bc_val,\n",
    "          'Pitch' : pitch_val\n",
    "      },\n",
    "      'Test' : {\n",
    "          'Batter' : b_test,\n",
    "          'Outcome' : o_test,\n",
    "          'IDs' : ids_test,\n",
    "          's_count' : sc_test,\n",
    "          'b_count' : bc_test,\n",
    "          'Pitch' : pitch_test\n",
    "      }\n",
    "  }\n",
    "  return sets\n",
    "\n",
    "input_output_tensors = get_train_val_test_sets(train_indices, val_indices, test_indices, input_output_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists from tensors\n",
    "\n",
    "batter_train = input_output_tensors['Training']['Batter']\n",
    "outcome_train = input_output_tensors['Training']['Outcome']\n",
    "ids_train = input_output_tensors['Training']['IDs']\n",
    "sc_train = input_output_tensors['Training']['s_count']\n",
    "bc_train = input_output_tensors['Training']['b_count']\n",
    "pitch_set_train = input_output_tensors['Training']['Pitch']\n",
    "\n",
    "\n",
    "batter_val = input_output_tensors['Validation']['Batter']\n",
    "outcome_val = input_output_tensors['Validation']['Outcome']\n",
    "ids_val = input_output_tensors['Validation']['IDs']\n",
    "sc_val = input_output_tensors['Validation']['s_count']\n",
    "bc_val = input_output_tensors['Validation']['b_count']\n",
    "pitch_set_val = input_output_tensors['Validation']['Pitch']\n",
    "\n",
    "\n",
    "batter_test = input_output_tensors['Test']['Batter']\n",
    "outcome_test = input_output_tensors['Test']['Outcome']\n",
    "ids_test = input_output_tensors['Test']['IDs']\n",
    "sc_test = input_output_tensors['Test']['s_count']\n",
    "bc_test = input_output_tensors['Test']['b_count']\n",
    "pitch_set_test = input_output_tensors['Test']['Pitch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle order of training data each time before training the model \n",
    "def randomize_order(b_tens, out_tens, ids, sc_tens, bc_tens, pitch_tens):\n",
    "  together = list(zip(list(b_tens), list(out_tens), list(ids), list(sc_tens), list(bc_tens), list(pitch_tens)))\n",
    "  import random\n",
    "  random.shuffle(together)\n",
    "  b_tens, out_tens, ids, sc_tens, bc_tens, pitch_tens = zip(*together)\n",
    "  return list(b_tens), list(out_tens), list(ids), list(sc_tens), list(bc_tens), list(pitch_tens)\n",
    "\n",
    "batter_train, outcome_train, ids_train, sc_train, bc_train, pitch_set_train = randomize_order(batter_train, outcome_train, ids_train, sc_train, bc_train, pitch_set_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to np arrays\n",
    "\n",
    "batter_train, outcome_train, sc_train, bc_train, pitch_set_train = np.array(batter_train), np.array(outcome_train), np.array(sc_train), np.array(bc_train), np.array(pitch_set_train)\n",
    "\n",
    "batter_val, outcome_val, sc_val, bc_val, pitch_set_val = np.array(batter_val), np.array(outcome_val), np.array(sc_val), np.array(bc_val), np.array(pitch_set_val)\n",
    "\n",
    "batter_test, outcome_test, sc_test, bc_test, pitch_set_test = np.array(batter_test), np.array(outcome_test), np.array(sc_test), np.array(bc_test), np.array(pitch_set_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Pred_Swing\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " batter (InputLayer)            [(None, 5, 5, 12)]   0           []                               \n",
      "                                                                                                  \n",
      " b_conv_1 (Conv2D)              (None, 5, 5, 32)     6176        ['batter[0][0]']                 \n",
      "                                                                                                  \n",
      " b_maxpool_1 (MaxPooling2D)     (None, 3, 3, 32)     0           ['b_conv_1[0][0]']               \n",
      "                                                                                                  \n",
      " b_conv_4 (Conv2D)              (None, 3, 3, 64)     12352       ['b_maxpool_1[0][0]']            \n",
      "                                                                                                  \n",
      " b_maxpool_2 (MaxPooling2D)     (None, 2, 2, 64)     0           ['b_conv_4[0][0]']               \n",
      "                                                                                                  \n",
      " b_conv_5 (Conv2D)              (None, 2, 2, 64)     36928       ['b_maxpool_2[0][0]']            \n",
      "                                                                                                  \n",
      " b_maxpool_3 (MaxPooling2D)     (None, 1, 1, 64)     0           ['b_conv_5[0][0]']               \n",
      "                                                                                                  \n",
      " b_conv_6 (Conv2D)              (None, 1, 1, 64)     24640       ['b_maxpool_3[0][0]']            \n",
      "                                                                                                  \n",
      " b_maxpool_4 (MaxPooling2D)     (None, 1, 1, 64)     0           ['b_conv_6[0][0]']               \n",
      "                                                                                                  \n",
      " pitch_input (InputLayer)       [(None, 5, 5, 6)]    0           []                               \n",
      "                                                                                                  \n",
      " b_conv_7 (Conv2D)              (None, 1, 1, 64)     16448       ['b_maxpool_4[0][0]']            \n",
      "                                                                                                  \n",
      " pitch_conv_1 (Conv2D)          (None, 5, 5, 32)     1760        ['pitch_input[0][0]']            \n",
      "                                                                                                  \n",
      " b_maxpool_5 (MaxPooling2D)     (None, 1, 1, 64)     0           ['b_conv_7[0][0]']               \n",
      "                                                                                                  \n",
      " pitch_maxpool_1 (MaxPooling2D)  (None, 3, 3, 32)    0           ['pitch_conv_1[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_batter (Flatten)       (None, 64)           0           ['b_maxpool_5[0][0]']            \n",
      "                                                                                                  \n",
      " strike_count (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " ball_count (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " flatten_pitch (Flatten)        (None, 288)          0           ['pitch_maxpool_1[0][0]']        \n",
      "                                                                                                  \n",
      " concat (Concatenate)           (None, 354)          0           ['flatten_batter[0][0]',         \n",
      "                                                                  'strike_count[0][0]',           \n",
      "                                                                  'ball_count[0][0]',             \n",
      "                                                                  'flatten_pitch[0][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          45440       ['concat[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           8256        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            65          ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 152,065\n",
      "Trainable params: 152,065\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## DEFINE THE MODEL\n",
    "\n",
    "\n",
    " \n",
    "#Batter layers\n",
    "b_input = Input(shape=(5, 5, 12), dtype='float32', name='batter')\n",
    "b_conv_1 = layers.Conv2D(32, (4, 4), activation='relu', padding='same', name='b_conv_1')(b_input)\n",
    "b_conv_2 = layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='b_conv_2')(b_conv_1)\n",
    "b_conv_3 = layers.Conv2D(32, (2, 2), activation='relu', padding='same', name='b_conv_3')(b_conv_2)\n",
    "b_maxpool_1 = layers.MaxPooling2D((2,2), padding='same', name='b_maxpool_1')(b_conv_1)\n",
    "b_conv_4 = layers.Conv2D(64, (2,3), activation='relu', padding='same', name='b_conv_4')(b_maxpool_1)\n",
    "b_maxpool_2 = layers.MaxPooling2D((2,2), padding='same', name='b_maxpool_2')(b_conv_4)\n",
    "b_conv_5 = layers.Conv2D(64, (3,3), activation='relu', padding='same', name='b_conv_5')(b_maxpool_2)\n",
    "b_maxpool_3 = layers.MaxPooling2D((2,2), padding='same', name='b_maxpool_3')(b_conv_5)\n",
    "b_conv_6 = layers.Conv2D(64, (2,3), activation='relu', padding='same', name='b_conv_6')(b_maxpool_3)\n",
    "b_maxpool_4 = layers.MaxPooling2D((2,2), padding='same', name='b_maxpool_4')(b_conv_6)\n",
    "b_conv_7 = layers.Conv2D(64, (2,2), activation='relu', padding='same', name='b_conv_7')(b_maxpool_4)\n",
    "b_maxpool_5 = layers.MaxPooling2D((2,2), padding='same', name='b_maxpool_5')(b_conv_7)\n",
    "flat_batter = layers.Flatten(name='flatten_batter')(b_maxpool_5)\n",
    "\n",
    "#Strike Count Layer\n",
    "strike_count = Input(shape=(1,), dtype='float32', name = \"strike_count\")\n",
    "#Ball Count Layer\n",
    "ball_count = Input(shape=(1,), dtype='float32', name = \"ball_count\")\n",
    "\n",
    "#Pitch Count Layer\n",
    "pitch_input = Input(shape=(5,5,6), dtype='float32', name = 'pitch_input')\n",
    "pitch_conv_1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='pitch_conv_1')(pitch_input)\n",
    "pitch_maxpool_1 = layers.MaxPooling2D((2,2), padding='same', name='pitch_maxpool_1')(pitch_conv_1)\n",
    "flat_pitch = layers.Flatten(name = \"flatten_pitch\")(pitch_maxpool_1)\n",
    "#Concatenate layer\n",
    "concatenated = layers.concatenate([flat_batter, strike_count, ball_count, flat_pitch], name='concat')\n",
    "dense_1 = layers.Dense(128, activation='sigmoid')(concatenated)\n",
    "dense_2 = layers.Dense(64, activation='sigmoid')(dense_1)\n",
    "\n",
    "\n",
    " \n",
    "#Sigmoid function\n",
    "output = layers.Dense(1, activation='sigmoid')(dense_2)\n",
    " \n",
    "network = models.Model([b_input, strike_count, ball_count, pitch_input], output, name='Pred_Swing')\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1155/1155 [==============================] - 71s 59ms/step - loss: 0.6132 - accuracy: 0.6634 - val_loss: 0.6042 - val_accuracy: 0.6719\n",
      "Epoch 2/50\n",
      "1155/1155 [==============================] - 69s 60ms/step - loss: 0.6060 - accuracy: 0.6714 - val_loss: 0.6027 - val_accuracy: 0.6737\n",
      "Epoch 3/50\n",
      "1155/1155 [==============================] - 71s 62ms/step - loss: 0.6052 - accuracy: 0.6718 - val_loss: 0.6037 - val_accuracy: 0.6722\n",
      "Epoch 4/50\n",
      "1155/1155 [==============================] - 67s 58ms/step - loss: 0.6044 - accuracy: 0.6722 - val_loss: 0.6034 - val_accuracy: 0.6736\n",
      "Epoch 5/50\n",
      "1155/1155 [==============================] - 74s 64ms/step - loss: 0.6034 - accuracy: 0.6735 - val_loss: 0.6108 - val_accuracy: 0.6663\n",
      "Epoch 6/50\n",
      "1155/1155 [==============================] - 70s 60ms/step - loss: 0.6028 - accuracy: 0.6736 - val_loss: 0.6002 - val_accuracy: 0.6760\n",
      "Epoch 7/50\n",
      "1155/1155 [==============================] - 71s 61ms/step - loss: 0.6020 - accuracy: 0.6741 - val_loss: 0.6008 - val_accuracy: 0.6752\n",
      "Epoch 8/50\n",
      "1155/1155 [==============================] - 72s 63ms/step - loss: 0.6017 - accuracy: 0.6744 - val_loss: 0.6003 - val_accuracy: 0.6754\n",
      "Epoch 9/50\n",
      "1155/1155 [==============================] - 69s 60ms/step - loss: 0.6012 - accuracy: 0.6745 - val_loss: 0.6003 - val_accuracy: 0.6751\n",
      "Epoch 10/50\n",
      "1155/1155 [==============================] - 74s 64ms/step - loss: 0.6011 - accuracy: 0.6746 - val_loss: 0.6002 - val_accuracy: 0.6747\n",
      "Epoch 11/50\n",
      "1155/1155 [==============================] - 70s 60ms/step - loss: 0.6006 - accuracy: 0.6748 - val_loss: 0.5963 - val_accuracy: 0.6791\n",
      "Epoch 12/50\n",
      "1155/1155 [==============================] - 71s 62ms/step - loss: 0.5953 - accuracy: 0.6792 - val_loss: 0.5975 - val_accuracy: 0.6758\n",
      "Epoch 13/50\n",
      "1155/1155 [==============================] - 74s 64ms/step - loss: 0.5936 - accuracy: 0.6805 - val_loss: 0.5915 - val_accuracy: 0.6822\n",
      "Epoch 14/50\n",
      "1155/1155 [==============================] - 75s 65ms/step - loss: 0.5928 - accuracy: 0.6814 - val_loss: 0.5913 - val_accuracy: 0.6828\n",
      "Epoch 15/50\n",
      "1155/1155 [==============================] - 78s 68ms/step - loss: 0.5922 - accuracy: 0.6820 - val_loss: 0.5904 - val_accuracy: 0.6841\n",
      "Epoch 16/50\n",
      "1155/1155 [==============================] - 76s 66ms/step - loss: 0.5917 - accuracy: 0.6821 - val_loss: 0.5930 - val_accuracy: 0.6807\n",
      "Epoch 17/50\n",
      "1155/1155 [==============================] - 80s 69ms/step - loss: 0.5914 - accuracy: 0.6823 - val_loss: 0.5964 - val_accuracy: 0.6773\n",
      "Epoch 18/50\n",
      "1155/1155 [==============================] - 80s 70ms/step - loss: 0.5909 - accuracy: 0.6824 - val_loss: 0.5905 - val_accuracy: 0.6831\n",
      "Epoch 19/50\n",
      "1155/1155 [==============================] - 81s 70ms/step - loss: 0.5907 - accuracy: 0.6830 - val_loss: 0.5898 - val_accuracy: 0.6848\n",
      "Epoch 20/50\n",
      "1155/1155 [==============================] - 80s 69ms/step - loss: 0.5907 - accuracy: 0.6826 - val_loss: 0.5899 - val_accuracy: 0.6845\n",
      "Epoch 21/50\n",
      "1155/1155 [==============================] - 78s 67ms/step - loss: 0.5904 - accuracy: 0.6831 - val_loss: 0.5903 - val_accuracy: 0.6835\n",
      "Epoch 22/50\n",
      "1155/1155 [==============================] - 79s 69ms/step - loss: 0.5902 - accuracy: 0.6829 - val_loss: 0.5924 - val_accuracy: 0.6820\n",
      "Epoch 23/50\n",
      "1155/1155 [==============================] - 74s 64ms/step - loss: 0.5901 - accuracy: 0.6835 - val_loss: 0.5918 - val_accuracy: 0.6819\n",
      "Epoch 24/50\n",
      "1155/1155 [==============================] - 78s 68ms/step - loss: 0.5899 - accuracy: 0.6836 - val_loss: 0.5911 - val_accuracy: 0.6831\n",
      "Epoch 25/50\n",
      "1155/1155 [==============================] - 73s 64ms/step - loss: 0.5897 - accuracy: 0.6841 - val_loss: 0.5911 - val_accuracy: 0.6831\n",
      "Epoch 26/50\n",
      "1155/1155 [==============================] - 60s 52ms/step - loss: 0.5850 - accuracy: 0.6876 - val_loss: 0.5879 - val_accuracy: 0.6857\n",
      "Epoch 32/50\n",
      "1155/1155 [==============================] - 64s 55ms/step - loss: 0.5847 - accuracy: 0.6879 - val_loss: 0.5873 - val_accuracy: 0.6859\n",
      "Epoch 33/50\n",
      "1155/1155 [==============================] - 69s 60ms/step - loss: 0.5846 - accuracy: 0.6880 - val_loss: 0.5868 - val_accuracy: 0.6868\n",
      "Epoch 34/50\n",
      "1155/1155 [==============================] - 73s 63ms/step - loss: 0.5842 - accuracy: 0.6883 - val_loss: 0.5869 - val_accuracy: 0.6870\n",
      "Epoch 35/50\n",
      "1155/1155 [==============================] - 74s 64ms/step - loss: 0.5840 - accuracy: 0.6885 - val_loss: 0.5863 - val_accuracy: 0.6870\n",
      "Epoch 36/50\n",
      "1155/1155 [==============================] - 66s 57ms/step - loss: 0.5830 - accuracy: 0.6890 - val_loss: 0.5883 - val_accuracy: 0.6852\n",
      "Epoch 41/50\n",
      "1155/1155 [==============================] - 72s 62ms/step - loss: 0.5830 - accuracy: 0.6893 - val_loss: 0.5890 - val_accuracy: 0.6857\n",
      "Epoch 42/50\n",
      "1155/1155 [==============================] - 71s 61ms/step - loss: 0.5827 - accuracy: 0.6892 - val_loss: 0.5868 - val_accuracy: 0.6855\n",
      "Epoch 43/50\n",
      "1155/1155 [==============================] - 78s 68ms/step - loss: 0.5825 - accuracy: 0.6898 - val_loss: 0.5877 - val_accuracy: 0.6858\n",
      "Epoch 44/50\n",
      "1155/1155 [==============================] - 75s 65ms/step - loss: 0.5823 - accuracy: 0.6897 - val_loss: 0.5869 - val_accuracy: 0.6868\n",
      "Epoch 45/50\n",
      "1155/1155 [==============================] - 74s 64ms/step - loss: 0.5821 - accuracy: 0.6898 - val_loss: 0.5864 - val_accuracy: 0.6867\n",
      "Epoch 46/50\n",
      "1155/1155 [==============================] - 73s 63ms/step - loss: 0.5818 - accuracy: 0.6901 - val_loss: 0.5876 - val_accuracy: 0.6866\n",
      "Epoch 47/50\n",
      "1155/1155 [==============================] - 74s 64ms/step - loss: 0.5815 - accuracy: 0.6902 - val_loss: 0.5869 - val_accuracy: 0.6878\n",
      "Epoch 48/50\n",
      "1155/1155 [==============================] - 75s 65ms/step - loss: 0.5813 - accuracy: 0.6904 - val_loss: 0.5892 - val_accuracy: 0.6848\n",
      "Epoch 49/50\n",
      "1155/1155 [==============================] - 66s 57ms/step - loss: 0.5809 - accuracy: 0.6906 - val_loss: 0.5880 - val_accuracy: 0.6862\n",
      "Epoch 50/50\n",
      "1155/1155 [==============================] - 75s 65ms/step - loss: 0.5805 - accuracy: 0.6910 - val_loss: 0.5882 - val_accuracy: 0.6858\n"
     ]
    }
   ],
   "source": [
    "# Compile and train the network \n",
    "opt = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "network.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = network.fit([ batter_train, sc_train, bc_train, pitch_set_train], outcome_train, epochs=50, batch_size=512, validation_data=([batter_val, sc_val, bc_val, pitch_set_val], outcome_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained network\n",
    "network.save(\"take_2015-2018.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED\n"
     ]
    }
   ],
   "source": [
    "# Test the network (loaded from model) and save the results\n",
    "network_test = keras.models.load_model(\"take_2015-2018.h5\")\n",
    "\n",
    "\n",
    "pred_results = network_test.predict([batter_test,sc_test,bc_test,pitch_set_test])\n",
    "\n",
    "    \n",
    "take_dict={\n",
    "    \"batter_test\":batter_test.tolist(),\n",
    "    \"ids_test\":ids_test,\n",
    "    \"outcome_test\":outcome_test.tolist(),\n",
    "    \"sc_test\":sc_test.tolist(),\n",
    "    \"bc_test\":bc_test.tolist(),\n",
    "    \"pitch_set_test\":pitch_set_test.tolist(),\n",
    "    \"pred_test\":pred_results.tolist()\n",
    "}\n",
    "    \n",
    "with open(\"take_test_predictions.json\", \"w\") as outfile: \n",
    "    json.dump(take_dict, outfile)\n",
    "print(\"SAVED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotting libraries and set defaults for Latex\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use(\"pdf\")\n",
    "matplotlib.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'thirds.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake_test_predictions.json\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m infile:\n\u001b[0;32m      4\u001b[0m     test_set \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(infile)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthirds.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m infile:\n\u001b[0;32m      7\u001b[0m     thirds \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(infile)\n\u001b[0;32m      9\u001b[0m batter_test\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(test_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatter_test\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'thirds.json'"
     ]
    }
   ],
   "source": [
    "# Open test results and aggregate between batter skill\n",
    "\n",
    "with open(\"take_test_predictions.json\") as infile:\n",
    "    test_set = json.load(infile)\n",
    "    \n",
    "with open(\"thirds.json\") as infile:\n",
    "    thirds = json.load(infile)\n",
    "    \n",
    "batter_test=np.array(test_set[\"batter_test\"])\n",
    "ids_test=np.array(test_set[\"ids_test\"])\n",
    "outcome_test=np.array(test_set[\"outcome_test\"])\n",
    "sc_test=np.array(test_set[\"sc_test\"])\n",
    "bc_test=np.array(test_set[\"bc_test\"])\n",
    "pitch_set_test=np.array(test_set[\"pitch_set_test\"])\n",
    "pred_test=np.array(test_set[\"pred_test\"])\n",
    "\n",
    "grouping_values = {}\n",
    "grouping_values[0] = {\"emp\":[],\"pred\":[]}\n",
    "grouping_values[1] = {\"emp\":[],\"pred\":[]}\n",
    "grouping_values[2] = {\"emp\":[],\"pred\":[]}\n",
    "\n",
    "b_not_in = 0\n",
    "b_in = 0\n",
    "\n",
    "for i in range(len(batter_test)):\n",
    "    b_id = str(ids_test[i][1])\n",
    "    if b_id in thirds[\"batters\"].keys():\n",
    "        b_group = thirds[\"batters\"][b_id]\n",
    "        b_in +=1\n",
    "        s_count = sc_test[i]\n",
    "        b_count = bc_test[i]\n",
    "\n",
    "\n",
    "        grouping_values[b_group][\"emp\"].append(outcome_test[i])\n",
    "        grouping_values[b_group][\"pred\"].append(pred_test[i])\n",
    "    else:\n",
    "        b_not_in += 1\n",
    "\n",
    "  \n",
    "grouping_averages = {}\n",
    "grouping_averages[0] = {\"emp\":[],\"pred\":[]}\n",
    "grouping_averages[1] = {\"emp\":[],\"pred\":[]}\n",
    "grouping_averages[2] = {\"emp\":[],\"pred\":[]}\n",
    "\n",
    "for group in grouping_values.keys():\n",
    "    emp_vals = np.array(grouping_values[group][\"emp\"])\n",
    "    pred_vals = np.array(grouping_values[group][\"pred\"])\n",
    "    grouping_averages[group][\"emp\"]=np.mean(emp_vals)\n",
    "    grouping_averages[group][\"pred\"]=np.mean(pred_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results aggregated between batter skill\n",
    "\n",
    "empirical = grouping_values\n",
    "labels = [0,1,2]\n",
    "printed_labels = [\"Weak\", \"Neutral\", \"Strong\"]\n",
    "emp_means = []\n",
    "val_means = []\n",
    "emp_yerr = []\n",
    "val_yerr = []\n",
    "\n",
    "for label in labels:\n",
    "    emp_at_count = np.array(empirical[label][\"emp\"])\n",
    "    emp_mean = np.mean(emp_at_count)\n",
    "    emp_std = np.std(emp_at_count)\n",
    "    emp_len = emp_at_count.shape[0]\n",
    "    emp_err = (1.96*emp_std/np.sqrt(emp_len))\n",
    "    print(type(emp_err))\n",
    "    emp_yerr.append(emp_err)\n",
    "    emp_means.append(emp_mean)\n",
    "\n",
    "    value_iter_at_count = np.array(empirical[label][\"pred\"])\n",
    "    val_mean = np.mean(value_iter_at_count)\n",
    "    val_std = np.std(value_iter_at_count)\n",
    "    val_len = value_iter_at_count.shape[0]\n",
    "    val_err = 2*(1.96*val_std/np.sqrt(val_len))\n",
    "    print(val_err)\n",
    "    val_yerr.append(val_err)\n",
    "    val_means.append(val_mean)\n",
    "\n",
    "print(emp_yerr)\n",
    "print(val_yerr)\n",
    "emp_yerr = emp_yerr\n",
    "data = np.arange(len(labels))  \n",
    "width = 0.3\n",
    "dist = .08\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(w=4.2, h=3.2)\n",
    "rects1 = ax.bar(data - width/2 - dist/2, emp_means, width, yerr= emp_yerr, label='Empirical', color = \"tomato\")\n",
    "rects2 = ax.bar(data + width/2 + dist/2, val_means, width, yerr= val_yerr, label='Predicted', color = \"dodgerblue\")\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                '%.3f' % float(height), rotation=90,\n",
    "                ha='center', va='bottom')\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "ax.set_ylim([0,1])\n",
    "ax.set_ylabel('Swing Probability') \n",
    "ax.set_xlabel('Batter Quality')\n",
    "ax.set_title(\"Swing Probabilities By Batter Performance\")\n",
    "ax.set_xticks(data)\n",
    "ax.set_xticklabels(printed_labels)\n",
    "ax.legend()\n",
    "plt.show()\n",
    "plt.savefig('take_batter_quality.pdf',dpi=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open test results and aggregate between counts\n",
    "\n",
    "with open(\"take_test_predictions.json\") as infile:\n",
    "    test_set = json.load(infile)\n",
    "batter_test=np.array(test_set[\"batter_test\"])\n",
    "ids_test=np.array(test_set[\"ids_test\"])\n",
    "outcome_test=np.array(test_set[\"outcome_test\"])\n",
    "sc_test=np.array(test_set[\"sc_test\"])\n",
    "bc_test=np.array(test_set[\"bc_test\"])\n",
    "pitch_set_test=np.array(test_set[\"pitch_set_test\"])\n",
    "pred_test=np.array(test_set[\"pred_test\"])\n",
    "\n",
    "count_probs={}\n",
    "\n",
    "for i in range(len(batter_test)):\n",
    "    b_id = ids_test[i][1]\n",
    "    s_count = sc_test[i]\n",
    "    b_count = bc_test[i]\n",
    "    count = str(int(b_count)) + str(int(s_count))\n",
    "    if count not in count_probs.keys():\n",
    "        count_probs[count]={\"emp\":[],\"pred\":[]}\n",
    "    count_probs[count][\"emp\"].append(outcome_test[i])\n",
    "    count_probs[count][\"pred\"].append(pred_test[i])\n",
    "    \n",
    "\n",
    "\n",
    "  \n",
    "del(count_probs[\"42\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results aggregated between counts\n",
    "\n",
    "empirical = count_probs\n",
    "labels = [\"00\",\"01\",\"02\",\"10\",\"11\",\"12\",\"20\",\"21\",\"22\",\"30\",\"31\",\"32\"]\n",
    "emp_means = []\n",
    "val_means = []\n",
    "emp_yerr = []\n",
    "val_yerr = []\n",
    "\n",
    "for label in labels:\n",
    "    emp_at_count = np.array(empirical[label][\"emp\"])\n",
    "    emp_mean = np.mean(emp_at_count)\n",
    "    emp_std = np.std(emp_at_count)\n",
    "    emp_len = emp_at_count.shape[0]\n",
    "    emp_err = (1.96*emp_std/np.sqrt(emp_len))\n",
    "    emp_yerr.append(emp_err)\n",
    "    emp_means.append(emp_mean)\n",
    "\n",
    "    value_iter_at_count = np.array(empirical[label][\"pred\"])[:,0]\n",
    "    val_mean = np.mean(value_iter_at_count)\n",
    "    val_std = np.std(value_iter_at_count)\n",
    "    val_len = value_iter_at_count.shape[0]\n",
    "    val_err = 2*(1.96*val_std/np.sqrt(val_len))\n",
    "    val_yerr.append(val_err)\n",
    "    val_means.append(val_mean)\n",
    "\n",
    "\n",
    "emp_yerr = emp_yerr\n",
    "data = np.arange(len(labels))  \n",
    "width = 0.3\n",
    "dist = .08\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(w=4.2, h=3.2)\n",
    "ax.bar(data - width/2 - dist/2, emp_means, width, yerr= emp_yerr, label='Empirical', color = \"tomato\")\n",
    "ax.bar(data + width/2 + dist/2, val_means, width, yerr= val_yerr, label='Predicted', color = \"dodgerblue\")\n",
    "\n",
    "\n",
    "\n",
    "ax.set_ylim([0,1])\n",
    "ax.set_ylabel('Swing Probability') \n",
    "ax.set_xlabel('Count')\n",
    "ax.set_title(\"Swing Probabilities Across Counts\")\n",
    "ax.set_xticks(data)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "plt.show()\n",
    "plt.savefig('take_counts.pdf',dpi=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print naive (predicts \"take\") and model accuracy\n",
    "print(\"Pr(swing): %s\"%np.mean(outcome_test))\n",
    "corrects = []\n",
    "\n",
    "for i in range(len(outcome_test)):\n",
    "    emp = outcome_test[i]\n",
    "    pred_raw = pred_test[i]\n",
    "    if pred_raw > .5:\n",
    "        pred = 1\n",
    "    else:\n",
    "        pred = 0\n",
    "    if emp == pred:\n",
    "        corrects.append(1)\n",
    "    else:\n",
    "        corrects.append(0)\n",
    "corrects = np.array(corrects)\n",
    "print(\"Accuracy: %s\"%np.mean(corrects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pr(take == outcome)\n",
    "\n",
    "1-0.39922498974019005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open test results and aggregate between counts, pitch types, and zones\n",
    "\n",
    "with open(\"take_test_predictions.json\") as infile:\n",
    "    test_set = json.load(infile)\n",
    "batter_test=np.array(test_set[\"batter_test\"])\n",
    "ids_test=np.array(test_set[\"ids_test\"])\n",
    "outcome_test=np.array(test_set[\"outcome_test\"])\n",
    "sc_test=np.array(test_set[\"sc_test\"])\n",
    "bc_test=np.array(test_set[\"bc_test\"])\n",
    "pitch_set_test=np.array(test_set[\"pitch_set_test\"])\n",
    "pred_test=np.array(test_set[\"pred_test\"])\n",
    "\n",
    "results = {}\n",
    "\n",
    "for i in range(len(batter_test)):\n",
    "    if i % 10000 == 0: print(i)\n",
    "    batter = batter_test[i]\n",
    "    batter_id = ids_test[i][1]\n",
    "    sc = sc_test[i]\n",
    "    bc = bc_test[i]\n",
    "    pitch_tensor = pitch_set_test[i]\n",
    "    row = new_df.loc[ids_test[i][2]]\n",
    "    pitch_type = row.pitch_type\n",
    "    zone = row.zones\n",
    "    \n",
    "    count = str(int(bc))+str(int(sc))\n",
    "    \n",
    "    swing = outcome_test[i]\n",
    "    pred_swing = pred_test[i]\n",
    "   \n",
    "    if count not in results.keys():\n",
    "        results[count] = {}\n",
    "    if pitch_type not in results[count].keys():\n",
    "        results[count][pitch_type] = {}\n",
    "    if zone not in results[count][pitch_type].keys():\n",
    "        results[count][pitch_type][zone] = {\"emp\":[],\"pred\":[]}\n",
    "    \n",
    "    results[count][pitch_type][zone][\"emp\"].append(swing)\n",
    "    results[count][pitch_type][zone][\"pred\"].append(pred_swing)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count in results.keys():\n",
    "    for pitch_type in results[count].keys():\n",
    "        for zone in results[count][pitch_type].keys():\n",
    "            print(\"Count: %s, Zone: %s, Pitch Type: %s\"%(count,zone,pitch_type))\n",
    "            print(\"%s instances\"%(len(results[count][pitch_type][zone][\"emp\"])))\n",
    "            print(\"Emperical Swing Percentage: %s\" %(np.mean(results[count][pitch_type][zone][\"emp\"])))\n",
    "            print(\"Predicted Swing Percentage: %s\" %(np.mean(results[count][pitch_type][zone][\"pred\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
