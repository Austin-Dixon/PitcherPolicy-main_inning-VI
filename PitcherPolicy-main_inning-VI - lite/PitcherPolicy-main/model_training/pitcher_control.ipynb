{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitcher Control Model: data cleaning, model training, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import appropriate libraries\n",
    "\n",
    "import pandas, json, requests, urllib, io, json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras        \n",
    "import numpy as np        \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from tensorflow.keras import models, layers, Input, optimizers, callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow_probability as tfp\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens pitcher tensors from json file\n",
    "\n",
    "def get_pitcher_tensors():\n",
    "    with open('pitcher_tensors.json') as json_file:\n",
    "        pitcher_tensors = json.load(json_file)\n",
    "    return pitcher_tensors\n",
    "\n",
    "\n",
    "pitcher_tensors = get_pitcher_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitsu\\AppData\\Local\\Temp\\ipykernel_13504\\3317877169.py:5: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  pitchData = pandas.read_csv(\"all_pitch.csv\", error_bad_lines=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>px</th>\n",
       "      <th>py</th>\n",
       "      <th>start_speed</th>\n",
       "      <th>code</th>\n",
       "      <th>pitch_type</th>\n",
       "      <th>ab_id</th>\n",
       "      <th>b_count</th>\n",
       "      <th>s_count</th>\n",
       "      <th>batter_id</th>\n",
       "      <th>event</th>\n",
       "      <th>pitcher_id</th>\n",
       "      <th>type</th>\n",
       "      <th>swing</th>\n",
       "      <th>result</th>\n",
       "      <th>zones</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.416</td>\n",
       "      <td>2.963</td>\n",
       "      <td>92.9</td>\n",
       "      <td>C</td>\n",
       "      <td>FF</td>\n",
       "      <td>2.015000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>572761</td>\n",
       "      <td>Groundout</td>\n",
       "      <td>452657</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>Strike</td>\n",
       "      <td>2</td>\n",
       "      <td>2a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>2.347</td>\n",
       "      <td>92.8</td>\n",
       "      <td>S</td>\n",
       "      <td>FF</td>\n",
       "      <td>2.015000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>572761</td>\n",
       "      <td>Groundout</td>\n",
       "      <td>452657</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Strike</td>\n",
       "      <td>4</td>\n",
       "      <td>4a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.518</td>\n",
       "      <td>3.284</td>\n",
       "      <td>94.1</td>\n",
       "      <td>F</td>\n",
       "      <td>FF</td>\n",
       "      <td>2.015000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>572761</td>\n",
       "      <td>Groundout</td>\n",
       "      <td>452657</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Foul</td>\n",
       "      <td>0</td>\n",
       "      <td>0a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.641</td>\n",
       "      <td>1.221</td>\n",
       "      <td>91.0</td>\n",
       "      <td>B</td>\n",
       "      <td>FF</td>\n",
       "      <td>2.015000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>572761</td>\n",
       "      <td>Groundout</td>\n",
       "      <td>452657</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>Ball</td>\n",
       "      <td>15</td>\n",
       "      <td>15b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.821</td>\n",
       "      <td>2.083</td>\n",
       "      <td>75.4</td>\n",
       "      <td>B</td>\n",
       "      <td>CU</td>\n",
       "      <td>2.015000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>572761</td>\n",
       "      <td>Groundout</td>\n",
       "      <td>452657</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>Ball</td>\n",
       "      <td>12</td>\n",
       "      <td>12b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     px     py  start_speed code pitch_type         ab_id  \\\n",
       "0           0  0.416  2.963         92.9    C         FF  2.015000e+09   \n",
       "1           1 -0.191  2.347         92.8    S         FF  2.015000e+09   \n",
       "2           2 -0.518  3.284         94.1    F         FF  2.015000e+09   \n",
       "3           3 -0.641  1.221         91.0    B         FF  2.015000e+09   \n",
       "4           4 -1.821  2.083         75.4    B         CU  2.015000e+09   \n",
       "\n",
       "   b_count  s_count  batter_id      event  pitcher_id type  swing  result  \\\n",
       "0      0.0      0.0     572761  Groundout      452657    S      0  Strike   \n",
       "1      0.0      1.0     572761  Groundout      452657    S      1  Strike   \n",
       "2      0.0      2.0     572761  Groundout      452657    S      1    Foul   \n",
       "3      0.0      2.0     572761  Groundout      452657    B      0    Ball   \n",
       "4      1.0      2.0     572761  Groundout      452657    B      0    Ball   \n",
       "\n",
       "   zones zone  \n",
       "0      2   2a  \n",
       "1      4   4a  \n",
       "2      0   0a  \n",
       "3     15  15b  \n",
       "4     12  12b  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gets the pitch data csv's for tensor creation from Github\n",
    "\n",
    "def get_total_pitch_data():\n",
    "\n",
    "  pitchData = pandas.read_csv(\"all_pitch.csv\", error_bad_lines=False)\n",
    "  pitchData = pitchData.rename({\"res\":\"result\"}, axis = 1)\n",
    "  del pitchData[\"zone\"]\n",
    "  pitchData[\"zone\"] = pitchData['zones']\n",
    "  pitchData[\"zones\"] = pitchData['zones'].map(lambda x: x.rstrip('aAbB')).astype(int)\n",
    "  \n",
    "  return pitchData\n",
    "\n",
    "\n",
    "total_pitch_data = get_total_pitch_data()\n",
    "total_pitch_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters pitches for 3-0 count\n",
    "def get_filtered_pitches(pitch_df):\n",
    "    return pitch_df[(pitch_df[\"b_count\"] == 3) & (pitch_df[\"s_count\"] == 0)]\n",
    "filtered_pitch_df = get_filtered_pitches(total_pitch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns distribution for x and y points\n",
    "def learn_bivar_gaussian(x,y):\n",
    "    emp_locs = [np.mean(x),np.mean(y)]\n",
    "    emp_sigma = np.cov(x,y)\n",
    "    emp_scale_tril = tf.linalg.cholesky(emp_sigma)\n",
    "    emp_dist = tfp.distributions.MultivariateNormalTriL(loc=emp_locs,scale_tril = emp_scale_tril)\n",
    "    \n",
    "    return emp_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns an error distribtion from the .95 most likely pitches\n",
    "def get_pruned_gaussian(pitcher_id, pitch_type, filtered_df):\n",
    "    pitcher_filtered_df = filtered_df[(filtered_df[\"pitcher_id\"]==pitcher_id) & (filtered_df[\"pitch_type\"]==pitch_type)]\n",
    "    x = pitcher_filtered_df[\"px\"].to_numpy()\n",
    "    y = pitcher_filtered_df[\"py\"].to_numpy()\n",
    "    orig_gaussian = learn_bivar_gaussian(x,y)\n",
    "    \n",
    "    liklihoods = {}\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        point_x = x[i]\n",
    "        point_y = y[i]\n",
    "        p_point = orig_gaussian.prob([point_x,point_y]).numpy()\n",
    "        liklihoods[p_point] = i\n",
    "    \n",
    "    sorted_liklihoods = sorted(liklihoods.keys())\n",
    "    portion_drop = .05\n",
    "    num_drop = int(portion_drop*len(x))\n",
    "    drop_indicies = []\n",
    "    \n",
    "    for i in range(num_drop):\n",
    "        drop_indicies.append(liklihoods[sorted_liklihoods[i]])\n",
    "    \n",
    "    pruned_x = []\n",
    "    pruned_y = []\n",
    "    for i in range(len(x)):\n",
    "        if i not in drop_indicies:\n",
    "            pruned_x.append(x[i])\n",
    "            pruned_y.append(y[i])\n",
    "            \n",
    "    pruned_x = np.array(pruned_x)\n",
    "    pruned_y = np.array(pruned_y)\n",
    "    \n",
    "    pruned_gaussian = learn_bivar_gaussian(pruned_x,pruned_y)\n",
    "    \n",
    "    return pruned_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845\n",
      "181\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "# Returns dictionary mapping pitchers to train/val/test test\n",
    "def get_train_val_test_pitchers(pitch_df):\n",
    "    unique_pitchers = list(pitch_df[\"pitcher_id\"].unique())\n",
    "    random.seed(0)\n",
    "    random.shuffle(unique_pitchers)\n",
    "\n",
    "    counter = 0\n",
    "    sets = {}\n",
    "    train_count = 0\n",
    "    val_count = 0\n",
    "    test_count = 0\n",
    "    for i,pitcher in enumerate(unique_pitchers):\n",
    "        \n",
    "        if i < len(unique_pitchers)*.7:\n",
    "            sets[pitcher] = \"train\"\n",
    "            train_count+=1\n",
    "        elif i < len(unique_pitchers) *.85:\n",
    "            sets[pitcher] = \"val\"\n",
    "            val_count+=1\n",
    "        else:\n",
    "            sets[pitcher] = \"test\"\n",
    "            test_count+=1\n",
    "       \n",
    "            \n",
    "    print(train_count)\n",
    "    print(val_count)\n",
    "    print(test_count)\n",
    "    return sets\n",
    "train_val_test_sets = get_train_val_test_pitchers(filtered_pitch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(571771, 15),\n",
       " (425772, 20),\n",
       " (430605, 23),\n",
       " (600301, 28),\n",
       " (573016, 42),\n",
       " (656954, 57),\n",
       " (501936, 61),\n",
       " (621249, 77),\n",
       " (543409, 80),\n",
       " (346797, 87),\n",
       " (541650, 90),\n",
       " (452061, 112),\n",
       " (607162, 119),\n",
       " (607951, 120),\n",
       " (489295, 143),\n",
       " (596101, 144),\n",
       " (217096, 149),\n",
       " (592712, 164),\n",
       " (605260, 169),\n",
       " (592781, 170),\n",
       " (622774, 171),\n",
       " (657117, 173),\n",
       " (572208, 187),\n",
       " (606995, 205),\n",
       " (458537, 210),\n",
       " (572990, 212),\n",
       " (595235, 214),\n",
       " (656803, 224),\n",
       " (435045, 246),\n",
       " (594867, 261),\n",
       " (623454, 274),\n",
       " (497807, 277),\n",
       " (464416, 278),\n",
       " (621142, 297),\n",
       " (658792, 302),\n",
       " (514669, 304),\n",
       " (502264, 332),\n",
       " (660853, 332),\n",
       " (573244, 334),\n",
       " (657681, 355),\n",
       " (592254, 356),\n",
       " (545064, 378),\n",
       " (518883, 388),\n",
       " (605143, 400),\n",
       " (500765, 407),\n",
       " (489002, 411),\n",
       " (430911, 436),\n",
       " (518489, 478),\n",
       " (542266, 508),\n",
       " (606959, 516),\n",
       " (506693, 545),\n",
       " (543903, 558),\n",
       " (605488, 558),\n",
       " (669203, 562),\n",
       " (453156, 568),\n",
       " (620982, 570),\n",
       " (648737, 596),\n",
       " (607455, 600),\n",
       " (640464, 624),\n",
       " (592473, 629),\n",
       " (502051, 659),\n",
       " (621056, 699),\n",
       " (622382, 726),\n",
       " (608328, 732),\n",
       " (572044, 751),\n",
       " (622795, 752),\n",
       " (594951, 782),\n",
       " (573127, 838),\n",
       " (592127, 838),\n",
       " (572955, 839),\n",
       " (656222, 873),\n",
       " (552640, 874),\n",
       " (489294, 880),\n",
       " (594792, 889),\n",
       " (572308, 922),\n",
       " (641154, 940),\n",
       " (622864, 945),\n",
       " (444436, 945),\n",
       " (462985, 965),\n",
       " (457732, 990),\n",
       " (605240, 1011),\n",
       " (542953, 1084),\n",
       " (642152, 1117),\n",
       " (425626, 1129),\n",
       " (542587, 1135),\n",
       " (594027, 1136),\n",
       " (605894, 1146),\n",
       " (285079, 1185),\n",
       " (641627, 1195),\n",
       " (542609, 1220),\n",
       " (519267, 1228),\n",
       " (663855, 1261),\n",
       " (543118, 1265),\n",
       " (641871, 1280),\n",
       " (656186, 1284),\n",
       " (641571, 1316),\n",
       " (542914, 1341),\n",
       " (596271, 1363),\n",
       " (456379, 1369),\n",
       " (595032, 1394),\n",
       " (572143, 1419),\n",
       " (605540, 1454),\n",
       " (459987, 1511),\n",
       " (621366, 1567),\n",
       " (434643, 1575),\n",
       " (571882, 1678),\n",
       " (580792, 1716),\n",
       " (468396, 1723),\n",
       " (488786, 1738),\n",
       " (641941, 1744),\n",
       " (669456, 1793),\n",
       " (659275, 1815),\n",
       " (628711, 1869),\n",
       " (435400, 1873),\n",
       " (641778, 1903),\n",
       " (518858, 1962),\n",
       " (592612, 1988),\n",
       " (453646, 2071),\n",
       " (519166, 2075),\n",
       " (607067, 2128),\n",
       " (670950, 2216),\n",
       " (543424, 2241),\n",
       " (592340, 2250),\n",
       " (571476, 2256),\n",
       " (543056, 2272),\n",
       " (451661, 2313),\n",
       " (548337, 2379),\n",
       " (605498, 2464),\n",
       " (501822, 2505),\n",
       " (656427, 2586),\n",
       " (595918, 2620),\n",
       " (430661, 2676),\n",
       " (527055, 2719),\n",
       " (502009, 2762),\n",
       " (592741, 2766),\n",
       " (421685, 2809),\n",
       " (502211, 2966),\n",
       " (477569, 3068),\n",
       " (491646, 3083),\n",
       " (605309, 3112),\n",
       " (435043, 3175),\n",
       " (502004, 3266),\n",
       " (571656, 3315),\n",
       " (456167, 3354),\n",
       " (519096, 3423),\n",
       " (474699, 3426),\n",
       " (467008, 3435),\n",
       " (493200, 3450),\n",
       " (461325, 3531),\n",
       " (519151, 3579),\n",
       " (408241, 3631),\n",
       " (502083, 3856),\n",
       " (473879, 3971),\n",
       " (543359, 4002),\n",
       " (607625, 4150),\n",
       " (502239, 4180),\n",
       " (598264, 4215),\n",
       " (605397, 4328),\n",
       " (543766, 4346),\n",
       " (450306, 4355),\n",
       " (572888, 4402),\n",
       " (656794, 4722),\n",
       " (504379, 5148),\n",
       " (543135, 5370),\n",
       " (572070, 5541),\n",
       " (543408, 5615),\n",
       " (450203, 6646),\n",
       " (608665, 6960),\n",
       " (628317, 7001),\n",
       " (547888, 7416),\n",
       " (445926, 7432),\n",
       " (605164, 7541),\n",
       " (570632, 7973),\n",
       " (573185, 8474),\n",
       " (502327, 9230),\n",
       " (519455, 9436),\n",
       " (543243, 9873),\n",
       " (456034, 10010),\n",
       " (461829, 12134),\n",
       " (519144, 12479)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of pitcher ids and number of pitches thrown\n",
    "\n",
    "test_ids=[]\n",
    "\n",
    "for pitcher in train_val_test_sets.keys():\n",
    "    if train_val_test_sets[pitcher] == \"test\":\n",
    "\n",
    "        test_ids.append((pitcher,total_pitch_data[total_pitch_data[\"pitcher_id\"]==pitcher].shape[0]))\n",
    "        \n",
    "test_ids.sort(key=lambda x: x[1])\n",
    "test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552\n",
      "115\n",
      "118\n"
     ]
    }
   ],
   "source": [
    "# Creates lists for input and output tensors\n",
    "\n",
    "def get_input_tensors(pitch_df, pitcher_embeddings,train_val_test_sets):\n",
    "    \n",
    "    pitches = ['FF', 'SL', 'FT', 'CH', 'FC', 'CU']\n",
    "\n",
    "    \n",
    "    train_pitcher = []\n",
    "    train_pitch = []\n",
    "    train_mu_x = []\n",
    "    train_mu_y = []\n",
    "    train_var_x = []\n",
    "    train_var_y = []\n",
    "    train_cov_x_y = []\n",
    "    \n",
    "    val_pitcher = []\n",
    "    val_pitch = []\n",
    "    val_mu_x = []\n",
    "    val_mu_y = []\n",
    "    val_var_x = []\n",
    "    val_var_y = []\n",
    "    val_cov_x_y = []\n",
    "    \n",
    "    test_pitcher = []\n",
    "    test_pitch = []\n",
    "    test_mu_x = []\n",
    "    test_mu_y = []\n",
    "    test_var_x = []\n",
    "    test_var_y = []\n",
    "    test_cov_x_y = []\n",
    "    test_ids = []\n",
    "  \n",
    "    \n",
    "    filtered_pitchers = pitch_df[\"pitcher_id\"].unique()\n",
    "    for i, pitcher in enumerate(filtered_pitchers):\n",
    "        pitcher_id = pitcher\n",
    "        pitcher_embedding = pitcher_embeddings[str(pitcher_id)]\n",
    "        tvt_set = train_val_test_sets[int(pitcher_id)]\n",
    "        \n",
    "        pitcher_df = pitch_df[pitch_df[\"pitcher_id\"]==pitcher_id]\n",
    "        pitch_types = pitcher_df[\"pitch_type\"].unique()\n",
    "        \n",
    "        for pitch in pitch_types:\n",
    "           \n",
    "            \n",
    "            shortened_df = pitcher_df[pitcher_df[\"pitch_type\"] == pitch]\n",
    "            \n",
    "            if shortened_df.shape[0] > 10:\n",
    "                pitch_embedding = np.zeros(len(pitches))\n",
    "                pitch_embedding[pitches.index(pitch)] = 1\n",
    "                \n",
    "                pruned_gaussian = get_pruned_gaussian(pitcher,pitch,shortened_df)\n",
    "\n",
    "                means = pruned_gaussian.mean().numpy()\n",
    "                cov_mat = pruned_gaussian.covariance().numpy()\n",
    "                mu_x = means[0]\n",
    "                mu_y = means[1]\n",
    "                var_x = cov_mat[0][0]\n",
    "                var_y = cov_mat[1][1]\n",
    "                cov_x_y = cov_mat[0][1]\n",
    "                \n",
    "      \n",
    "\n",
    "\n",
    "                if tvt_set == \"train\":\n",
    "                    train_pitcher.append(pitcher_embedding)\n",
    "                    train_pitch.append(pitch_embedding)\n",
    "                    train_mu_x.append(mu_x)\n",
    "                    train_mu_y.append(mu_y)\n",
    "                    train_var_x.append(var_x)\n",
    "                    train_var_y.append(var_y)\n",
    "                    train_cov_x_y.append(cov_x_y)\n",
    "                elif tvt_set == \"val\":\n",
    "                    val_pitcher.append(pitcher_embedding)\n",
    "                    val_pitch.append(pitch_embedding)\n",
    "                    val_mu_x.append(mu_x)\n",
    "                    val_mu_y.append(mu_y)\n",
    "                    val_var_x.append(var_x)\n",
    "                    val_var_y.append(var_y)\n",
    "                    val_cov_x_y.append(cov_x_y)\n",
    "                elif tvt_set == \"test\":\n",
    "                    test_pitcher.append(pitcher_embedding)\n",
    "                    test_pitch.append(pitch_embedding)\n",
    "                    test_mu_x.append(mu_x)\n",
    "                    test_mu_y.append(mu_y)\n",
    "                    test_var_x.append(var_x)\n",
    "                    test_var_y.append(var_y)\n",
    "                    test_cov_x_y.append(cov_x_y)\n",
    "                    test_ids.append((pitcher_id, pitch))\n",
    "        \n",
    "    print(len(train_pitcher))\n",
    "    print(len(val_pitcher))\n",
    "    print(len(test_pitcher))\n",
    "    tensors={\n",
    "        \"train\":{\n",
    "            \"pitcher\" : np.array(train_pitcher),\n",
    "            \"pitch\" : np.array(train_pitch),\n",
    "            \"mu_x\" : np.array(train_mu_x),\n",
    "            \"mu_y\" : np.array(train_mu_y),\n",
    "            \"var_x\" : np.array(train_var_x),\n",
    "            \"var_y\" : np.array(train_var_y),\n",
    "            \"cov_x_y\" : np.array(train_cov_x_y)\n",
    "        },\n",
    "        \"val\":{\n",
    "            \"pitcher\" : np.array(val_pitcher),\n",
    "            \"pitch\" : np.array(val_pitch),\n",
    "            \"mu_x\" : np.array(val_mu_x),\n",
    "            \"mu_y\" : np.array(val_mu_y),\n",
    "            \"var_x\" : np.array(val_var_x),\n",
    "            \"var_y\" : np.array(val_var_y),\n",
    "            \"cov_x_y\" : np.array(val_cov_x_y)\n",
    "        },\n",
    "        \"test\":{\n",
    "            \"pitcher\" : np.array(test_pitcher),\n",
    "            \"pitch\" : np.array(test_pitch),\n",
    "            \"mu_x\" : np.array(test_mu_x),\n",
    "            \"mu_y\" : np.array(test_mu_y),\n",
    "            \"var_x\" : np.array(test_var_x),\n",
    "            \"var_y\" : np.array(test_var_y),\n",
    "            \"cov_x_y\" : np.array(test_cov_x_y),\n",
    "            \"ids\": np.array(test_ids)\n",
    "        }\n",
    "    }\n",
    "   \n",
    "    return tensors\n",
    "\n",
    "\n",
    "tensors = get_input_tensors(filtered_pitch_df, pitcher_tensors, train_val_test_sets)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates indiviudal lists from i/o tensor dictionaries\n",
    "\n",
    "train_pitcher = tensors[\"train\"][\"pitcher\"]\n",
    "train_pitch = tensors[\"train\"][\"pitch\"]\n",
    "train_mu_x = tensors[\"train\"][\"mu_x\"]\n",
    "train_mu_y = tensors[\"train\"][\"mu_y\"]\n",
    "train_var_x = tensors[\"train\"][\"var_x\"]\n",
    "train_var_y = tensors[\"train\"][\"var_y\"]\n",
    "train_cov_x_y = tensors[\"train\"][\"cov_x_y\"]\n",
    "\n",
    "val_pitcher = tensors[\"val\"][\"pitcher\"]\n",
    "val_pitch = tensors[\"val\"][\"pitch\"]\n",
    "val_mu_x = tensors[\"val\"][\"mu_x\"]\n",
    "val_mu_y = tensors[\"val\"][\"mu_y\"]\n",
    "val_var_x = tensors[\"val\"][\"var_x\"]\n",
    "val_var_y = tensors[\"val\"][\"var_y\"]\n",
    "val_cov_x_y = tensors[\"val\"][\"cov_x_y\"]\n",
    "\n",
    "test_pitcher = tensors[\"test\"][\"pitcher\"]\n",
    "test_pitch = tensors[\"test\"][\"pitch\"]\n",
    "test_mu_x = tensors[\"test\"][\"mu_x\"]\n",
    "test_mu_y = tensors[\"test\"][\"mu_y\"]\n",
    "test_var_x = tensors[\"test\"][\"var_x\"]\n",
    "test_var_y = tensors[\"test\"][\"var_y\"]\n",
    "test_cov_x_y = tensors[\"test\"][\"cov_x_y\"]\n",
    "test_ids = tensors[\"test\"][\"ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_order(train_pitcher, train_pitch, train_mu_x, train_mu_y, train_var_x, train_var_y, train_cov_x_y):\n",
    "  together = list(zip(list(train_pitcher), list(train_pitch), list(train_mu_x), list(train_mu_y), list(train_var_x), list(train_var_y), list(train_cov_x_y)))\n",
    "  import random\n",
    "  random.shuffle(together)\n",
    "  train_pitcher, train_pitch, train_mu_x, train_mu_y, train_var_x, train_var_y, train_cov_x_y = zip(*together)\n",
    "  return list(train_pitcher), list(train_pitch), list(train_mu_x), list(train_mu_y), list(train_var_x), list(train_var_y), list(train_cov_x_y)\n",
    "\n",
    "\n",
    "train_pitcher, train_pitch, train_mu_x, train_mu_y, train_var_x, train_var_y, train_cov_x_y = randomize_order(train_pitcher, train_pitch, train_mu_x, train_mu_y, train_var_x, train_var_y, train_cov_x_y)\n",
    "train_pitcher = np.array(train_pitcher)\n",
    "train_pitch = np.array(train_pitch)\n",
    "train_mu_x = np.array(train_mu_x)\n",
    "train_mu_y = np.array(train_mu_y)\n",
    "train_var_x = np.array(train_var_x)\n",
    "train_var_y = np.array(train_var_y)\n",
    "train_cov_x_y = np.array(train_cov_x_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " pitcher (InputLayer)           [(None, 5, 5, 12)]   0           []                               \n",
      "                                                                                                  \n",
      " p_conv_1 (Conv2D)              (None, 5, 5, 32)     6176        ['pitcher[0][0]']                \n",
      "                                                                                                  \n",
      " p_maxpool_1 (MaxPooling2D)     (None, 3, 3, 32)     0           ['p_conv_1[0][0]']               \n",
      "                                                                                                  \n",
      " p_conv_4 (Conv2D)              (None, 3, 3, 64)     20544       ['p_maxpool_1[0][0]']            \n",
      "                                                                                                  \n",
      " p_maxpool_2 (MaxPooling2D)     (None, 2, 2, 64)     0           ['p_conv_4[0][0]']               \n",
      "                                                                                                  \n",
      " p_conv_5 (Conv2D)              (None, 2, 2, 64)     32832       ['p_maxpool_2[0][0]']            \n",
      "                                                                                                  \n",
      " p_maxpool_3 (MaxPooling2D)     (None, 1, 1, 64)     0           ['p_conv_5[0][0]']               \n",
      "                                                                                                  \n",
      " p_conv_6 (Conv2D)              (None, 1, 1, 64)     24640       ['p_maxpool_3[0][0]']            \n",
      "                                                                                                  \n",
      " p_maxpool_4 (MaxPooling2D)     (None, 1, 1, 64)     0           ['p_conv_6[0][0]']               \n",
      "                                                                                                  \n",
      " p_conv_7 (Conv2D)              (None, 1, 1, 64)     16448       ['p_maxpool_4[0][0]']            \n",
      "                                                                                                  \n",
      " p_maxpool_5 (MaxPooling2D)     (None, 1, 1, 64)     0           ['p_conv_7[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_pitcher (Flatten)      (None, 64)           0           ['p_maxpool_5[0][0]']            \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " concat (Concatenate)           (None, 70)           0           ['flatten_pitcher[0][0]',        \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 100)          7100        ['concat[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 50)           5050        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 25)           1275        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            26          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1)            26          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            26          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 1)            26          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            26          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 114,195\n",
      "Trainable params: 114,195\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## DEFINE THE MODEL\n",
    "\n",
    "\n",
    "#Network Input: Pitcher embedding\n",
    "p_input = Input(shape=(5, 5, 12), dtype='float32', name='pitcher')\n",
    "p_conv_1 = layers.Conv2D(32, (4, 4), activation='relu', padding='same', name='p_conv_1')(p_input)\n",
    "p_conv_2 = layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='p_conv_2')(p_conv_1)\n",
    "p_conv_3 = layers.Conv2D(32, (2, 2), activation='relu', padding='same', name='p_conv_3')(p_conv_2)\n",
    "p_maxpool_1 = layers.MaxPooling2D((2,2), padding='same', name='p_maxpool_1')(p_conv_1)\n",
    "p_conv_4 = layers.Conv2D(64, (2,5), activation='relu', padding='same', name='p_conv_4')(p_maxpool_1)\n",
    "p_maxpool_2 = layers.MaxPooling2D((2,2), padding='same', name='p_maxpool_2')(p_conv_4)\n",
    "p_conv_5 = layers.Conv2D(64, (2,4), activation='relu', padding='same', name='p_conv_5')(p_maxpool_2)\n",
    "p_maxpool_3 = layers.MaxPooling2D((2,2), padding='same', name='p_maxpool_3')(p_conv_5)\n",
    "p_conv_6 = layers.Conv2D(64, (2,3), activation='relu', padding='same', name='p_conv_6')(p_maxpool_3)\n",
    "p_maxpool_4 = layers.MaxPooling2D((2,2), padding='same', name='p_maxpool_4')(p_conv_6)\n",
    "p_conv_7 = layers.Conv2D(64, (2,2), activation='relu', padding='same', name='p_conv_7')(p_maxpool_4)\n",
    "p_maxpool_5 = layers.MaxPooling2D((2,2), padding='same', name='p_maxpool_5')(p_conv_7)\n",
    "flat_pitcher = layers.Flatten(name='flatten_pitcher')(p_maxpool_5)\n",
    " \n",
    "input_pitch_embedding = Input(shape=(6))\n",
    "\n",
    "concatenated = layers.concatenate([flat_pitcher, input_pitch_embedding], name='concat')\n",
    "\n",
    "\n",
    "#Dense Layers\n",
    "\n",
    "Layer_1 = layers.Dense(100,activation=\"sigmoid\")(concatenated)\n",
    "Layer_2 = layers.Dense(50, activation = \"sigmoid\")(Layer_1)\n",
    "Layer_3 = layers.Dense(25,activation=\"sigmoid\")(Layer_2)\n",
    "\n",
    "#Output Layers\n",
    "mu_x = layers.Dense(1, activation=\"linear\")(Layer_3)\n",
    "mu_y = layers.Dense(1, activation=\"linear\")(Layer_3)\n",
    "var_x = layers.Dense(1, activation=\"linear\")(Layer_3)\n",
    "var_y = layers.Dense(1, activation=\"linear\")(Layer_3)\n",
    "cov_x_y = layers.Dense(1, activation=\"linear\")(Layer_3)\n",
    "\n",
    "\n",
    "model = models.Model(inputs=[p_input, input_pitch_embedding], outputs=[mu_x, mu_y, var_x, var_y, cov_x_y])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "552/552 [==============================] - 4s 6ms/step - loss: 0.4113 - dense_3_loss: 0.0761 - dense_4_loss: 0.1887 - dense_5_loss: 0.0402 - dense_6_loss: 0.0562 - dense_7_loss: 0.0500 - val_loss: 0.2408 - val_dense_3_loss: 0.0630 - val_dense_4_loss: 0.0538 - val_dense_5_loss: 0.0404 - val_dense_6_loss: 0.0480 - val_dense_7_loss: 0.0357\n",
      "Epoch 2/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2504 - dense_3_loss: 0.0701 - dense_4_loss: 0.0566 - dense_5_loss: 0.0322 - dense_6_loss: 0.0545 - dense_7_loss: 0.0370 - val_loss: 0.2438 - val_dense_3_loss: 0.0632 - val_dense_4_loss: 0.0578 - val_dense_5_loss: 0.0387 - val_dense_6_loss: 0.0477 - val_dense_7_loss: 0.0364\n",
      "Epoch 3/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2516 - dense_3_loss: 0.0683 - dense_4_loss: 0.0579 - dense_5_loss: 0.0329 - dense_6_loss: 0.0554 - dense_7_loss: 0.0370 - val_loss: 0.2653 - val_dense_3_loss: 0.0690 - val_dense_4_loss: 0.0644 - val_dense_5_loss: 0.0482 - val_dense_6_loss: 0.0475 - val_dense_7_loss: 0.0362\n",
      "Epoch 4/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2489 - dense_3_loss: 0.0687 - dense_4_loss: 0.0577 - dense_5_loss: 0.0327 - dense_6_loss: 0.0529 - dense_7_loss: 0.0369 - val_loss: 0.2431 - val_dense_3_loss: 0.0631 - val_dense_4_loss: 0.0538 - val_dense_5_loss: 0.0393 - val_dense_6_loss: 0.0484 - val_dense_7_loss: 0.0386\n",
      "Epoch 5/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2511 - dense_3_loss: 0.0701 - dense_4_loss: 0.0584 - dense_5_loss: 0.0317 - dense_6_loss: 0.0535 - dense_7_loss: 0.0374 - val_loss: 0.2560 - val_dense_3_loss: 0.0631 - val_dense_4_loss: 0.0654 - val_dense_5_loss: 0.0388 - val_dense_6_loss: 0.0527 - val_dense_7_loss: 0.0360\n",
      "Epoch 6/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2500 - dense_3_loss: 0.0695 - dense_4_loss: 0.0575 - dense_5_loss: 0.0328 - dense_6_loss: 0.0537 - dense_7_loss: 0.0366 - val_loss: 0.2559 - val_dense_3_loss: 0.0766 - val_dense_4_loss: 0.0539 - val_dense_5_loss: 0.0394 - val_dense_6_loss: 0.0483 - val_dense_7_loss: 0.0377\n",
      "Epoch 7/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2470 - dense_3_loss: 0.0683 - dense_4_loss: 0.0572 - dense_5_loss: 0.0319 - dense_6_loss: 0.0534 - dense_7_loss: 0.0363 - val_loss: 0.2420 - val_dense_3_loss: 0.0651 - val_dense_4_loss: 0.0554 - val_dense_5_loss: 0.0382 - val_dense_6_loss: 0.0475 - val_dense_7_loss: 0.0359\n",
      "Epoch 8/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2468 - dense_3_loss: 0.0674 - dense_4_loss: 0.0569 - dense_5_loss: 0.0322 - dense_6_loss: 0.0544 - dense_7_loss: 0.0358 - val_loss: 0.2549 - val_dense_3_loss: 0.0678 - val_dense_4_loss: 0.0540 - val_dense_5_loss: 0.0464 - val_dense_6_loss: 0.0498 - val_dense_7_loss: 0.0368\n",
      "Epoch 9/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2485 - dense_3_loss: 0.0689 - dense_4_loss: 0.0578 - dense_5_loss: 0.0321 - dense_6_loss: 0.0533 - dense_7_loss: 0.0364 - val_loss: 0.2422 - val_dense_3_loss: 0.0640 - val_dense_4_loss: 0.0550 - val_dense_5_loss: 0.0400 - val_dense_6_loss: 0.0478 - val_dense_7_loss: 0.0354\n",
      "Epoch 10/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2445 - dense_3_loss: 0.0683 - dense_4_loss: 0.0562 - dense_5_loss: 0.0320 - dense_6_loss: 0.0528 - dense_7_loss: 0.0353 - val_loss: 0.2599 - val_dense_3_loss: 0.0641 - val_dense_4_loss: 0.0697 - val_dense_5_loss: 0.0411 - val_dense_6_loss: 0.0494 - val_dense_7_loss: 0.0356\n",
      "Epoch 11/50\n",
      "552/552 [==============================] - 2s 5ms/step - loss: 0.2471 - dense_3_loss: 0.0687 - dense_4_loss: 0.0564 - dense_5_loss: 0.0320 - dense_6_loss: 0.0545 - dense_7_loss: 0.0356 - val_loss: 0.2497 - val_dense_3_loss: 0.0640 - val_dense_4_loss: 0.0567 - val_dense_5_loss: 0.0381 - val_dense_6_loss: 0.0514 - val_dense_7_loss: 0.0395\n",
      "Epoch 12/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2439 - dense_3_loss: 0.0670 - dense_4_loss: 0.0566 - dense_5_loss: 0.0315 - dense_6_loss: 0.0530 - dense_7_loss: 0.0358 - val_loss: 0.2434 - val_dense_3_loss: 0.0639 - val_dense_4_loss: 0.0538 - val_dense_5_loss: 0.0384 - val_dense_6_loss: 0.0519 - val_dense_7_loss: 0.0355\n",
      "Epoch 13/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2456 - dense_3_loss: 0.0681 - dense_4_loss: 0.0564 - dense_5_loss: 0.0320 - dense_6_loss: 0.0535 - dense_7_loss: 0.0355 - val_loss: 0.2420 - val_dense_3_loss: 0.0630 - val_dense_4_loss: 0.0553 - val_dense_5_loss: 0.0387 - val_dense_6_loss: 0.0488 - val_dense_7_loss: 0.0362\n",
      "Epoch 14/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2439 - dense_3_loss: 0.0686 - dense_4_loss: 0.0562 - dense_5_loss: 0.0310 - dense_6_loss: 0.0525 - dense_7_loss: 0.0356 - val_loss: 0.2405 - val_dense_3_loss: 0.0632 - val_dense_4_loss: 0.0554 - val_dense_5_loss: 0.0390 - val_dense_6_loss: 0.0476 - val_dense_7_loss: 0.0354\n",
      "Epoch 15/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2469 - dense_3_loss: 0.0682 - dense_4_loss: 0.0581 - dense_5_loss: 0.0317 - dense_6_loss: 0.0531 - dense_7_loss: 0.0358 - val_loss: 0.2464 - val_dense_3_loss: 0.0635 - val_dense_4_loss: 0.0561 - val_dense_5_loss: 0.0426 - val_dense_6_loss: 0.0485 - val_dense_7_loss: 0.0356\n",
      "Epoch 16/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2433 - dense_3_loss: 0.0680 - dense_4_loss: 0.0565 - dense_5_loss: 0.0311 - dense_6_loss: 0.0525 - dense_7_loss: 0.0352 - val_loss: 0.2454 - val_dense_3_loss: 0.0634 - val_dense_4_loss: 0.0563 - val_dense_5_loss: 0.0381 - val_dense_6_loss: 0.0520 - val_dense_7_loss: 0.0355\n",
      "Epoch 17/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2456 - dense_3_loss: 0.0671 - dense_4_loss: 0.0571 - dense_5_loss: 0.0319 - dense_6_loss: 0.0537 - dense_7_loss: 0.0358 - val_loss: 0.2392 - val_dense_3_loss: 0.0642 - val_dense_4_loss: 0.0538 - val_dense_5_loss: 0.0382 - val_dense_6_loss: 0.0476 - val_dense_7_loss: 0.0355\n",
      "Epoch 18/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2429 - dense_3_loss: 0.0670 - dense_4_loss: 0.0561 - dense_5_loss: 0.0309 - dense_6_loss: 0.0531 - dense_7_loss: 0.0358 - val_loss: 0.2439 - val_dense_3_loss: 0.0687 - val_dense_4_loss: 0.0538 - val_dense_5_loss: 0.0382 - val_dense_6_loss: 0.0475 - val_dense_7_loss: 0.0357\n",
      "Epoch 19/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2427 - dense_3_loss: 0.0674 - dense_4_loss: 0.0556 - dense_5_loss: 0.0315 - dense_6_loss: 0.0529 - dense_7_loss: 0.0354 - val_loss: 0.2471 - val_dense_3_loss: 0.0630 - val_dense_4_loss: 0.0577 - val_dense_5_loss: 0.0390 - val_dense_6_loss: 0.0500 - val_dense_7_loss: 0.0375\n",
      "Epoch 20/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2445 - dense_3_loss: 0.0683 - dense_4_loss: 0.0562 - dense_5_loss: 0.0315 - dense_6_loss: 0.0525 - dense_7_loss: 0.0359 - val_loss: 0.2403 - val_dense_3_loss: 0.0631 - val_dense_4_loss: 0.0548 - val_dense_5_loss: 0.0386 - val_dense_6_loss: 0.0476 - val_dense_7_loss: 0.0362\n",
      "Epoch 21/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2432 - dense_3_loss: 0.0681 - dense_4_loss: 0.0553 - dense_5_loss: 0.0312 - dense_6_loss: 0.0530 - dense_7_loss: 0.0356 - val_loss: 0.2377 - val_dense_3_loss: 0.0629 - val_dense_4_loss: 0.0536 - val_dense_5_loss: 0.0383 - val_dense_6_loss: 0.0474 - val_dense_7_loss: 0.0354\n",
      "Epoch 22/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2435 - dense_3_loss: 0.0684 - dense_4_loss: 0.0563 - dense_5_loss: 0.0315 - dense_6_loss: 0.0525 - dense_7_loss: 0.0347 - val_loss: 0.2408 - val_dense_3_loss: 0.0630 - val_dense_4_loss: 0.0541 - val_dense_5_loss: 0.0389 - val_dense_6_loss: 0.0482 - val_dense_7_loss: 0.0367\n",
      "Epoch 23/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2437 - dense_3_loss: 0.0680 - dense_4_loss: 0.0562 - dense_5_loss: 0.0309 - dense_6_loss: 0.0529 - dense_7_loss: 0.0358 - val_loss: 0.2402 - val_dense_3_loss: 0.0633 - val_dense_4_loss: 0.0545 - val_dense_5_loss: 0.0381 - val_dense_6_loss: 0.0483 - val_dense_7_loss: 0.0359\n",
      "Epoch 24/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2431 - dense_3_loss: 0.0677 - dense_4_loss: 0.0558 - dense_5_loss: 0.0308 - dense_6_loss: 0.0534 - dense_7_loss: 0.0354 - val_loss: 0.2415 - val_dense_3_loss: 0.0629 - val_dense_4_loss: 0.0543 - val_dense_5_loss: 0.0382 - val_dense_6_loss: 0.0504 - val_dense_7_loss: 0.0357\n",
      "Epoch 25/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2438 - dense_3_loss: 0.0670 - dense_4_loss: 0.0564 - dense_5_loss: 0.0313 - dense_6_loss: 0.0530 - dense_7_loss: 0.0361 - val_loss: 0.2419 - val_dense_3_loss: 0.0647 - val_dense_4_loss: 0.0549 - val_dense_5_loss: 0.0391 - val_dense_6_loss: 0.0475 - val_dense_7_loss: 0.0358\n",
      "Epoch 26/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2419 - dense_3_loss: 0.0674 - dense_4_loss: 0.0556 - dense_5_loss: 0.0312 - dense_6_loss: 0.0523 - dense_7_loss: 0.0354 - val_loss: 0.2437 - val_dense_3_loss: 0.0676 - val_dense_4_loss: 0.0535 - val_dense_5_loss: 0.0384 - val_dense_6_loss: 0.0481 - val_dense_7_loss: 0.0362\n",
      "Epoch 27/50\n",
      "552/552 [==============================] - 2s 5ms/step - loss: 0.2434 - dense_3_loss: 0.0675 - dense_4_loss: 0.0562 - dense_5_loss: 0.0313 - dense_6_loss: 0.0527 - dense_7_loss: 0.0358 - val_loss: 0.2401 - val_dense_3_loss: 0.0631 - val_dense_4_loss: 0.0538 - val_dense_5_loss: 0.0380 - val_dense_6_loss: 0.0478 - val_dense_7_loss: 0.0374\n",
      "Epoch 28/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2432 - dense_3_loss: 0.0683 - dense_4_loss: 0.0552 - dense_5_loss: 0.0312 - dense_6_loss: 0.0529 - dense_7_loss: 0.0357 - val_loss: 0.2439 - val_dense_3_loss: 0.0644 - val_dense_4_loss: 0.0553 - val_dense_5_loss: 0.0400 - val_dense_6_loss: 0.0487 - val_dense_7_loss: 0.0355\n",
      "Epoch 29/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2406 - dense_3_loss: 0.0662 - dense_4_loss: 0.0556 - dense_5_loss: 0.0312 - dense_6_loss: 0.0527 - dense_7_loss: 0.0349 - val_loss: 0.2448 - val_dense_3_loss: 0.0652 - val_dense_4_loss: 0.0557 - val_dense_5_loss: 0.0391 - val_dense_6_loss: 0.0488 - val_dense_7_loss: 0.0360\n",
      "Epoch 30/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2375 - dense_3_loss: 0.0648 - dense_4_loss: 0.0559 - dense_5_loss: 0.0312 - dense_6_loss: 0.0527 - dense_7_loss: 0.0330 - val_loss: 0.2477 - val_dense_3_loss: 0.0652 - val_dense_4_loss: 0.0569 - val_dense_5_loss: 0.0434 - val_dense_6_loss: 0.0479 - val_dense_7_loss: 0.0342\n",
      "Epoch 31/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2367 - dense_3_loss: 0.0650 - dense_4_loss: 0.0560 - dense_5_loss: 0.0316 - dense_6_loss: 0.0524 - dense_7_loss: 0.0316 - val_loss: 0.2442 - val_dense_3_loss: 0.0646 - val_dense_4_loss: 0.0539 - val_dense_5_loss: 0.0426 - val_dense_6_loss: 0.0492 - val_dense_7_loss: 0.0340\n",
      "Epoch 32/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2335 - dense_3_loss: 0.0630 - dense_4_loss: 0.0552 - dense_5_loss: 0.0319 - dense_6_loss: 0.0526 - dense_7_loss: 0.0308 - val_loss: 0.2387 - val_dense_3_loss: 0.0605 - val_dense_4_loss: 0.0560 - val_dense_5_loss: 0.0373 - val_dense_6_loss: 0.0486 - val_dense_7_loss: 0.0362\n",
      "Epoch 33/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2345 - dense_3_loss: 0.0629 - dense_4_loss: 0.0561 - dense_5_loss: 0.0314 - dense_6_loss: 0.0528 - dense_7_loss: 0.0313 - val_loss: 0.2369 - val_dense_3_loss: 0.0601 - val_dense_4_loss: 0.0545 - val_dense_5_loss: 0.0372 - val_dense_6_loss: 0.0498 - val_dense_7_loss: 0.0353\n",
      "Epoch 34/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2303 - dense_3_loss: 0.0609 - dense_4_loss: 0.0549 - dense_5_loss: 0.0315 - dense_6_loss: 0.0520 - dense_7_loss: 0.0309 - val_loss: 0.2362 - val_dense_3_loss: 0.0611 - val_dense_4_loss: 0.0550 - val_dense_5_loss: 0.0375 - val_dense_6_loss: 0.0490 - val_dense_7_loss: 0.0337\n",
      "Epoch 35/50\n",
      "552/552 [==============================] - 2s 5ms/step - loss: 0.2285 - dense_3_loss: 0.0611 - dense_4_loss: 0.0556 - dense_5_loss: 0.0307 - dense_6_loss: 0.0514 - dense_7_loss: 0.0298 - val_loss: 0.2333 - val_dense_3_loss: 0.0594 - val_dense_4_loss: 0.0544 - val_dense_5_loss: 0.0371 - val_dense_6_loss: 0.0486 - val_dense_7_loss: 0.0338\n",
      "Epoch 36/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2286 - dense_3_loss: 0.0612 - dense_4_loss: 0.0553 - dense_5_loss: 0.0317 - dense_6_loss: 0.0510 - dense_7_loss: 0.0294 - val_loss: 0.2352 - val_dense_3_loss: 0.0607 - val_dense_4_loss: 0.0542 - val_dense_5_loss: 0.0375 - val_dense_6_loss: 0.0490 - val_dense_7_loss: 0.0338\n",
      "Epoch 37/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2267 - dense_3_loss: 0.0595 - dense_4_loss: 0.0542 - dense_5_loss: 0.0315 - dense_6_loss: 0.0515 - dense_7_loss: 0.0301 - val_loss: 0.2434 - val_dense_3_loss: 0.0647 - val_dense_4_loss: 0.0568 - val_dense_5_loss: 0.0394 - val_dense_6_loss: 0.0490 - val_dense_7_loss: 0.0335\n",
      "Epoch 38/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2251 - dense_3_loss: 0.0589 - dense_4_loss: 0.0543 - dense_5_loss: 0.0312 - dense_6_loss: 0.0513 - dense_7_loss: 0.0294 - val_loss: 0.2387 - val_dense_3_loss: 0.0598 - val_dense_4_loss: 0.0585 - val_dense_5_loss: 0.0371 - val_dense_6_loss: 0.0503 - val_dense_7_loss: 0.0330\n",
      "Epoch 39/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2257 - dense_3_loss: 0.0593 - dense_4_loss: 0.0546 - dense_5_loss: 0.0308 - dense_6_loss: 0.0510 - dense_7_loss: 0.0299 - val_loss: 0.2401 - val_dense_3_loss: 0.0594 - val_dense_4_loss: 0.0565 - val_dense_5_loss: 0.0386 - val_dense_6_loss: 0.0500 - val_dense_7_loss: 0.0357\n",
      "Epoch 40/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2398 - dense_3_loss: 0.0655 - dense_4_loss: 0.0556 - dense_5_loss: 0.0311 - dense_6_loss: 0.0529 - dense_7_loss: 0.0347 - val_loss: 0.2431 - val_dense_3_loss: 0.0634 - val_dense_4_loss: 0.0547 - val_dense_5_loss: 0.0383 - val_dense_6_loss: 0.0499 - val_dense_7_loss: 0.0369\n",
      "Epoch 41/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2421 - dense_3_loss: 0.0676 - dense_4_loss: 0.0555 - dense_5_loss: 0.0310 - dense_6_loss: 0.0523 - dense_7_loss: 0.0357 - val_loss: 0.2486 - val_dense_3_loss: 0.0638 - val_dense_4_loss: 0.0536 - val_dense_5_loss: 0.0450 - val_dense_6_loss: 0.0493 - val_dense_7_loss: 0.0368\n",
      "Epoch 42/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2437 - dense_3_loss: 0.0677 - dense_4_loss: 0.0563 - dense_5_loss: 0.0312 - dense_6_loss: 0.0528 - dense_7_loss: 0.0357 - val_loss: 0.2505 - val_dense_3_loss: 0.0689 - val_dense_4_loss: 0.0538 - val_dense_5_loss: 0.0383 - val_dense_6_loss: 0.0536 - val_dense_7_loss: 0.0359\n",
      "Epoch 43/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2370 - dense_3_loss: 0.0647 - dense_4_loss: 0.0551 - dense_5_loss: 0.0309 - dense_6_loss: 0.0521 - dense_7_loss: 0.0342 - val_loss: 0.2396 - val_dense_3_loss: 0.0599 - val_dense_4_loss: 0.0578 - val_dense_5_loss: 0.0372 - val_dense_6_loss: 0.0512 - val_dense_7_loss: 0.0336\n",
      "Epoch 44/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2269 - dense_3_loss: 0.0596 - dense_4_loss: 0.0541 - dense_5_loss: 0.0314 - dense_6_loss: 0.0515 - dense_7_loss: 0.0303 - val_loss: 0.2395 - val_dense_3_loss: 0.0590 - val_dense_4_loss: 0.0578 - val_dense_5_loss: 0.0395 - val_dense_6_loss: 0.0494 - val_dense_7_loss: 0.0339\n",
      "Epoch 45/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2256 - dense_3_loss: 0.0581 - dense_4_loss: 0.0547 - dense_5_loss: 0.0311 - dense_6_loss: 0.0517 - dense_7_loss: 0.0301 - val_loss: 0.2318 - val_dense_3_loss: 0.0582 - val_dense_4_loss: 0.0540 - val_dense_5_loss: 0.0380 - val_dense_6_loss: 0.0491 - val_dense_7_loss: 0.0326\n",
      "Epoch 46/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2243 - dense_3_loss: 0.0586 - dense_4_loss: 0.0533 - dense_5_loss: 0.0316 - dense_6_loss: 0.0516 - dense_7_loss: 0.0292 - val_loss: 0.2450 - val_dense_3_loss: 0.0594 - val_dense_4_loss: 0.0630 - val_dense_5_loss: 0.0381 - val_dense_6_loss: 0.0507 - val_dense_7_loss: 0.0337\n",
      "Epoch 47/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2230 - dense_3_loss: 0.0574 - dense_4_loss: 0.0550 - dense_5_loss: 0.0306 - dense_6_loss: 0.0514 - dense_7_loss: 0.0286 - val_loss: 0.2384 - val_dense_3_loss: 0.0571 - val_dense_4_loss: 0.0553 - val_dense_5_loss: 0.0386 - val_dense_6_loss: 0.0548 - val_dense_7_loss: 0.0326\n",
      "Epoch 48/50\n",
      "552/552 [==============================] - 3s 5ms/step - loss: 0.2217 - dense_3_loss: 0.0560 - dense_4_loss: 0.0540 - dense_5_loss: 0.0309 - dense_6_loss: 0.0513 - dense_7_loss: 0.0294 - val_loss: 0.2389 - val_dense_3_loss: 0.0576 - val_dense_4_loss: 0.0595 - val_dense_5_loss: 0.0387 - val_dense_6_loss: 0.0494 - val_dense_7_loss: 0.0336\n",
      "Epoch 49/50\n",
      "552/552 [==============================] - 2s 4ms/step - loss: 0.2190 - dense_3_loss: 0.0558 - dense_4_loss: 0.0520 - dense_5_loss: 0.0311 - dense_6_loss: 0.0517 - dense_7_loss: 0.0284 - val_loss: 0.2345 - val_dense_3_loss: 0.0588 - val_dense_4_loss: 0.0532 - val_dense_5_loss: 0.0379 - val_dense_6_loss: 0.0511 - val_dense_7_loss: 0.0334\n",
      "Epoch 50/50\n",
      "552/552 [==============================] - 2s 5ms/step - loss: 0.2206 - dense_3_loss: 0.0554 - dense_4_loss: 0.0536 - dense_5_loss: 0.0312 - dense_6_loss: 0.0517 - dense_7_loss: 0.0287 - val_loss: 0.2319 - val_dense_3_loss: 0.0588 - val_dense_4_loss: 0.0535 - val_dense_5_loss: 0.0379 - val_dense_6_loss: 0.0518 - val_dense_7_loss: 0.0298\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss = \"mse\")\n",
    "history_cache = model.fit([train_pitcher, train_pitch],\n",
    "                          [train_mu_x, train_mu_y, train_var_x, train_var_y, train_cov_x_y],\n",
    "                          validation_data = ([val_pitcher, val_pitch],[val_mu_x, val_mu_y, val_var_x, val_var_y, val_cov_x_y]),\n",
    "                          epochs=50,\n",
    "                          batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "\n",
    "model.save(\"error_2015-2018.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for test set\n",
    "\n",
    "network_test = keras.models.load_model(\"error_2015-2018.h5\")\n",
    "\n",
    "\n",
    "pred_results = np.array(network_test.predict([test_pitcher, test_pitch]))\n",
    "\n",
    "    \n",
    "error_dict={\n",
    "    \"pitcher_test\":test_pitcher.tolist(),\n",
    "    \"mu_x_test\":test_mu_x.tolist(),\n",
    "    \"mu_y_test\":test_mu_y.tolist(),\n",
    "    \"var_x_test\":test_var_x.tolist(),\n",
    "    \"var_y_test\":test_var_y.tolist(),\n",
    "    \"cov_x_y_test\":test_cov_x_y.tolist(),\n",
    "    \"pitch_set_test\":test_pitch.tolist(),\n",
    "    \"pred_test\":pred_results.tolist(),\n",
    "    \"ids_test\":test_ids.tolist()\n",
    "}\n",
    "    \n",
    "with open(\"error_test_predictions.json\", \"w\") as outfile: \n",
    "    json.dump(error_dict, outfile)\n",
    "print(\"SAVED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates mean squared error between two arrays\n",
    "\n",
    "def calc_mse(array_1,array_2):\n",
    "    diff = array_1 - array_2\n",
    "    return np.mean(np.square(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance X MSE\n",
      "0.03391881813704184\n",
      "Variance Y MSE\n",
      "0.05602068900593914\n",
      "Covariance MSE\n",
      "0.028544813799379745\n"
     ]
    }
   ],
   "source": [
    "# Open test predictions and print MSE for the three learned parameters\n",
    "with open(\"error_test_predictions.json\") as infile:\n",
    "    test_set = json.load(infile)\n",
    "true_var_x = np.array(test_set[\"var_x_test\"])\n",
    "true_var_y = np.array(test_set[\"var_y_test\"])\n",
    "true_cov_x_y= np.array(test_set[\"cov_x_y_test\"])\n",
    "\n",
    "pred_test = np.array(test_set[\"pred_test\"])\n",
    "\n",
    "pred_var_x = pred_test[2,:,0]\n",
    "pred_var_y = pred_test[3,:,0]\n",
    "pred_cov_x_y = pred_test[4,:,0]\n",
    "\n",
    "\n",
    "var_x_mse = calc_mse(true_var_x, pred_var_x)\n",
    "var_y_mse = calc_mse(true_var_y, pred_var_y)\n",
    "cov_x_y_mse = calc_mse(true_cov_x_y, pred_cov_x_y)\n",
    "\n",
    "print(\"Variance X MSE\")\n",
    "print(var_x_mse)\n",
    "print(\"Variance Y MSE\")\n",
    "print(var_y_mse)\n",
    "print(\"Covariance MSE\")\n",
    "print(cov_x_y_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'thirds.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror_test_predictions.json\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m infile:\n\u001b[0;32m      5\u001b[0m     test_set \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(infile)\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthirds.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m infile:\n\u001b[0;32m      9\u001b[0m     thirds \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(infile)\n\u001b[0;32m     12\u001b[0m true_var_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(test_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvar_x_test\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'thirds.json'"
     ]
    }
   ],
   "source": [
    "# Open test predictions and aggregate across pitcher quality for fourseem fastball (\"FF\")\n",
    "\n",
    "\n",
    "with open(\"error_test_predictions.json\") as infile:\n",
    "    test_set = json.load(infile)\n",
    "    \n",
    "    \n",
    "with open(\"thirds.json\") as infile:\n",
    "    thirds = json.load(infile)\n",
    "    \n",
    "    \n",
    "true_var_x = np.array(test_set[\"var_x_test\"])\n",
    "true_var_y = np.array(test_set[\"var_y_test\"])\n",
    "true_cov_x_y= np.array(test_set[\"cov_x_y_test\"])\n",
    "\n",
    "pred_test = np.array(test_set[\"pred_test\"])\n",
    "\n",
    "pred_var_x = pred_test[2,:,0]\n",
    "pred_var_y = pred_test[3,:,0]\n",
    "pred_cov_x_y = pred_test[4,:,0]\n",
    "\n",
    "counter = 0\n",
    "grouping_values = {}\n",
    "grouping_values[0] = {\"emp\":[],\"pred\":[]}\n",
    "grouping_values[1] = {\"emp\":[],\"pred\":[]}\n",
    "grouping_values[2] = {\"emp\":[],\"pred\":[]}\n",
    "for i in range(len(test_set[\"pitcher_test\"])):\n",
    "    if test_set[\"ids_test\"][i][1] == \"FF\":\n",
    "        counter+=1\n",
    "        print(counter)\n",
    "        pitcher_id = str(test_set[\"ids_test\"][i][0])\n",
    "        group = thirds[\"pitchers\"][pitcher_id]\n",
    "        grouping_values[group][\"emp\"].append([test_set[\"var_x_test\"][i],test_set[\"var_y_test\"][i],test_set[\"cov_x_y_test\"][i]])\n",
    "        grouping_values[group][\"pred\"].append([pred_var_x[i],pred_var_y[i],pred_cov_x_y[i]])\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "grouping_averages = {}\n",
    "grouping_averages[0] = {\"emp\":[],\"pred\":[]}\n",
    "grouping_averages[1] = {\"emp\":[],\"pred\":[]}\n",
    "grouping_averages[2] = {\"emp\":[],\"pred\":[]}\n",
    "\n",
    "for group in grouping_values.keys():\n",
    "    emp_vals = np.array(grouping_values[group][\"emp\"])\n",
    "    pred_vals = np.array(grouping_values[group][\"pred\"])\n",
    "    grouping_averages[group][\"emp\"]=np.mean(emp_vals,axis=0)\n",
    "    grouping_averages[group][\"pred\"]=np.mean(pred_vals,axis=0)\n",
    "    print(group)\n",
    "    print(len(emp_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotting libraries and set format for Latex\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use(\"pdf\")\n",
    "matplotlib.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution paramters across groups of pitcher skill\n",
    "\n",
    "emp_var_x = []\n",
    "emp_var_y = []\n",
    "\n",
    "pred_var_x = []\n",
    "pred_var_y = []\n",
    "\n",
    "\n",
    "for group in grouping_averages.keys():\n",
    "    emp_var_x.append(grouping_averages[group][\"emp\"][0])\n",
    "    emp_var_y.append(grouping_averages[group][\"emp\"][1])\n",
    "\n",
    "    pred_var_x.append(grouping_averages[group][\"pred\"][0])\n",
    "    pred_var_y.append(grouping_averages[group][\"pred\"][1])\n",
    "\n",
    "    \n",
    "width = 0.15  # the width of the bars\n",
    "dist = .08\n",
    "\n",
    "\n",
    "groups = [\"Weak\",\"Average\",\"Strong\"]\n",
    "\n",
    "\n",
    "\n",
    "x = np.arange(len(groups))\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(w=4, h=3.5)\n",
    "rects1 = ax.bar(x - width-width*1/2-dist-dist*1/2, emp_var_x, width, label='Emp Var X', edgecolor= \"dodgerblue\",hatch=\"///\", color=\"white\", alpha = .99, linewidth=2)\n",
    "rects2 = ax.bar(x-width*1/2 -dist*1/2, pred_var_x, width, label='Pred Var X',color=\"white\", edgecolor= \"dodgerblue\",linewidth=2)\n",
    "rects3 = ax.bar(x + width-width*1/2+dist*1/2, emp_var_y, width, label='Emp Var Y', edgecolor= \"tomato\",color=\"white\",hatch=\"///\", alpha = .99,linewidth=2)\n",
    "rects4 = ax.bar(x + width*2-width*1/2 +dist+dist*1/2, pred_var_y, width, label='Pred Var Y', color=\"white\",edgecolor= \"tomato\",linewidth=2)\n",
    "\n",
    "\n",
    "ax.set_ylabel(\"Variance\")\n",
    "ax.set_xlabel(\"Pitcher Group\")\n",
    "ax.set_title('FF Distribution Across Pitcher Groups')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(groups)\n",
    "ax.legend()\n",
    "plt.ylim((0,1.1))\n",
    "\n",
    "\n",
    "#fig.tight_layout()\n",
    "\n",
    "def autolabel(bars):\n",
    "\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        print(height)\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., 1.05*height,\n",
    "                '%.3f' % float(height), rotation=90,\n",
    "                ha='center', va='bottom')\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "autolabel(rects4)\n",
    "plt.legend(loc=\"upper center\", ncol = 2)\n",
    "plt.show()\n",
    "plt.savefig('fourseem_dist.pdf',dpi=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots countour lines of empirical and predicted distributions \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_distribution(pitcher_id,pitch_type)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    pruned_gaussian = get_pruned_gaussian(pitcher_id,pitch_type,filtered_pitch_df)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    emp_locs = pruned_gaussian.mean().numpy()\n",
    "    emp_sigma = pruned_gaussian.covariance().numpy()\n",
    "    emp_scale_tril = tf.linalg.cholesky(emp_sigma)\n",
    "    emp_dist = tfp.distributions.MultivariateNormalTriL(loc=emp_locs,scale_tril = emp_scale_tril)\n",
    "\n",
    "    print(emp_sigma)\n",
    "    N= 100000\n",
    "\n",
    "    emp_x = emp_dist.sample(N)\n",
    "    emp_x1 = emp_x[:, 0].numpy()\n",
    "    emp_x2 = emp_x[:, 1].numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    pitcher_embedding = np.array(pitcher_tensors[str(pitcher_id)])\n",
    "    pitches = ['FF', 'SL', 'FT', 'CH', 'FC', 'CU']\n",
    "    pitch = np.zeros(6)\n",
    "    pitch[pitches.index(pitch_type)] = 1\n",
    "\n",
    "    mu_x_pred, mu_y_pred, var_x_pred, var_y_pred, cov_x_y_pred = network_test.predict([np.array([pitcher_embedding]),np.array([pitch])])\n",
    "\n",
    "    locs = [mu_x_pred[0][0],mu_y_pred[0][0]]\n",
    "    sigma = [[var_x_pred[0][0], cov_x_y_pred[0][0]],\n",
    "             [cov_x_y_pred[0][0], var_y_pred[0][0]]]\n",
    "    scale_tril = tf.linalg.cholesky(sigma)\n",
    "    dist = tfp.distributions.MultivariateNormalTriL(loc=locs,scale_tril = scale_tril)\n",
    "\n",
    "    print(sigma)\n",
    "    N = 100000\n",
    "    x = dist.sample(N)\n",
    "    x1 = x[:, 0].numpy()\n",
    "    x2 = x[:, 1].numpy()\n",
    "\n",
    "    plt.title(\"Emperically Derived (Blue) vs Predicted (Red) Guassian\")\n",
    "    sns.kdeplot(x1, x2, color = \"red\")\n",
    "    sns.kdeplot(emp_x1, emp_x2, color = \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates distributions across zones for a given pitcher and pitch type for empirical pitches thrown, empirically learned pruned Gaussian distribution, and predicted pruned Gaussian distribution\n",
    "\n",
    "pitcher_id = 461829\n",
    "pitch_type = \"FF\"\n",
    "network_test = keras.models.load_model(\"error_2015-2018.h5\")\n",
    "\n",
    "pruned_gaussian = get_pruned_gaussian(pitcher_id,pitch_type,filtered_pitch_df)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,3.5))\n",
    "\n",
    "\n",
    "data = filtered_pitch_df[(filtered_pitch_df[\"pitcher_id\"]==pitcher_id) & (filtered_pitch_df[\"pitch_type\"]==pitch_type)][[\"px\",\"py\"]].to_numpy()\n",
    "print(data)\n",
    "x1 = data[:, 0]\n",
    "x2 = data[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "emp_locs = pruned_gaussian.mean().numpy()\n",
    "emp_sigma = pruned_gaussian.covariance().numpy()\n",
    "emp_scale_tril = tf.linalg.cholesky(emp_sigma)\n",
    "emp_dist = tfp.distributions.MultivariateNormalTriL(loc=emp_locs,scale_tril = emp_scale_tril)\n",
    "print(emp_locs)\n",
    "print(emp_sigma)\n",
    "N= 100000\n",
    "\n",
    "emp_x = emp_dist.sample(N)\n",
    "emp_x1 = emp_x[:, 0].numpy()\n",
    "emp_x2 = emp_x[:, 1].numpy()\n",
    "\n",
    "\n",
    "pitcher_embedding = np.array(pitcher_tensors[str(pitcher_id)])\n",
    "pitches = ['FF', 'SL', 'FT', 'CH', 'FC', 'CU']\n",
    "pitch = np.zeros(6)\n",
    "pitch[pitches.index(pitch_type)] = 1\n",
    "\n",
    "mu_x_pred, mu_y_pred, var_x_pred, var_y_pred, cov_x_y_pred = network_test.predict([np.array([pitcher_embedding]),np.array([pitch])])\n",
    "\n",
    "locs = [mu_x_pred[0][0],mu_y_pred[0][0]]\n",
    "sigma = [[var_x_pred[0][0], cov_x_y_pred[0][0]],\n",
    "         [cov_x_y_pred[0][0], var_y_pred[0][0]]]\n",
    "scale_tril = tf.linalg.cholesky(sigma)\n",
    "pred_dist = tfp.distributions.MultivariateNormalTriL(loc=locs,scale_tril = scale_tril)\n",
    "\n",
    "print(sigma)\n",
    "\n",
    "pred_data = pred_dist.sample(N)\n",
    "pred_x1 = pred_data[:, 0].numpy()\n",
    "pred_x2 = pred_data[:, 1].numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_zone(x,y):\n",
    "    LEFT_X = -0.831\n",
    "    MID_LEFT_X = -0.277\n",
    "    MID_RIGHT_X = 0.277\n",
    "    RIGHT_X = 0.831\n",
    "\n",
    "    TOP_Y = 1.074 +2.599\n",
    "    MID_TOP_Y = 0.358 +2.599\n",
    "    MID_BOT_Y = -0.358 +2.599\n",
    "    BOT_Y = -1.074 +2.599\n",
    "    \n",
    "    \n",
    "    if x< LEFT_X:\n",
    "        if y< BOT_Y:\n",
    "            return 14\n",
    "        elif y<MID_BOT_Y:\n",
    "            return 12\n",
    "        elif y<MID_TOP_Y:\n",
    "            return 12\n",
    "        elif y<TOP_Y:\n",
    "            return 12\n",
    "        else:\n",
    "            return 9\n",
    "    elif x<MID_LEFT_X:\n",
    "        if y< BOT_Y:\n",
    "            return 15\n",
    "        elif y<MID_BOT_Y:\n",
    "            return 6\n",
    "        elif y<MID_TOP_Y:\n",
    "            return 3\n",
    "        elif y<TOP_Y:\n",
    "            return 0\n",
    "        else:\n",
    "            return 10\n",
    "    elif x<MID_RIGHT_X:\n",
    "        if y< BOT_Y:\n",
    "            return 15   \n",
    "        elif y<MID_BOT_Y:\n",
    "            return 7\n",
    "        elif y<MID_TOP_Y:\n",
    "            return 4\n",
    "        elif y<TOP_Y:\n",
    "            return 1\n",
    "        else:\n",
    "            return 10\n",
    "    elif x<RIGHT_X:\n",
    "        if y< BOT_Y:\n",
    "            return 15    \n",
    "        elif y<MID_BOT_Y:\n",
    "            return 8\n",
    "        elif y<MID_TOP_Y:\n",
    "            return 5\n",
    "        elif y<TOP_Y:\n",
    "            return 2\n",
    "        else:\n",
    "            return 10\n",
    "    else:\n",
    "        if y< BOT_Y:\n",
    "            return 16\n",
    "        elif y<MID_BOT_Y:\n",
    "            return 13   \n",
    "        elif y<MID_TOP_Y:\n",
    "            return 13\n",
    "        elif y<TOP_Y:\n",
    "            return 13\n",
    "        else: \n",
    "            return 11\n",
    "        \n",
    "sample = np.zeros((len(emp_x),2))\n",
    "sample[:,0] = emp_x1\n",
    "sample[:,1] = emp_x2\n",
    "\n",
    "\n",
    "dist_zones = []\n",
    "\n",
    "LEFT_X = -0.831\n",
    "MID_LEFT_X = -0.277\n",
    "MID_RIGHT_X = 0.277\n",
    "RIGHT_X = 0.831\n",
    "\n",
    "TOP_Y = 1.074 +2.599\n",
    "MID_TOP_Y = 0.358 +2.599\n",
    "MID_BOT_Y = -0.358 +2.599\n",
    "BOT_Y = -1.074 +2.599\n",
    "\n",
    "\n",
    "emp_zones = []\n",
    "\n",
    "for point in data:\n",
    "    x = point[0]\n",
    "    y = point[1]\n",
    "    zone = get_zone(x,y)\n",
    "    emp_zones.append(zone)\n",
    "    \n",
    "\n",
    "dist_zones = []\n",
    "\n",
    "for point in sample:\n",
    "    x = point[0]\n",
    "    y = point[1]\n",
    "    zone = get_zone(x,y)\n",
    "    dist_zones.append(zone)\n",
    "\n",
    "\n",
    "\n",
    "pred_zones = []\n",
    "\n",
    "for point in pred_data:\n",
    "    x = point[0]\n",
    "    y = point[1]\n",
    "    zone = get_zone(x,y)\n",
    "    pred_zones.append(zone)\n",
    "    \n",
    "emp_zone_counts = pandas.Series(np.array(emp_zones)).value_counts(normalize = True)\n",
    "    \n",
    "dist_zone_counts = pandas.Series(np.array(dist_zones)).value_counts(normalize = True)\n",
    "\n",
    "pred_zone_counts = pandas.Series(np.array(pred_zones)).value_counts(normalize = True)\n",
    "\n",
    "    \n",
    "def get_x_y_zone_frequencies(series):\n",
    "    data = {1:{},2:{},3:{},4:{},5:{}}\n",
    "    \n",
    "    \n",
    "    for zone, freq in series.iteritems():\n",
    "    \n",
    "    \n",
    "        if zone == 0:\n",
    "            data[2][4] = freq\n",
    "        if zone == 1:\n",
    "            data[3][4] = freq\n",
    "        if zone == 2:\n",
    "            data[4][4] = freq\n",
    "        if zone == 3:\n",
    "            data[2][3] = freq\n",
    "        if zone == 4:\n",
    "            data[3][3] = freq\n",
    "        if zone == 5:\n",
    "            data[4][3] = freq\n",
    "        if zone == 6:\n",
    "            data[2][2] = freq\n",
    "        if zone == 7:\n",
    "            data[3][2] = freq\n",
    "        if zone == 8:\n",
    "            data[4][2] = freq\n",
    "        if zone == 9:\n",
    "            data[1][5] = freq\n",
    "        if zone == 10:\n",
    "            data[2][5] = freq\n",
    "            data[3][5] = freq\n",
    "            data[4][5] = freq\n",
    "        if zone == 11:\n",
    "            data[5][5] = freq\n",
    "        if zone == 12:\n",
    "            data[1][2] = freq\n",
    "            data[1][3] = freq\n",
    "            data[1][4] = freq\n",
    "        if zone == 13:\n",
    "            data[5][2] = freq\n",
    "            data[5][3] = freq\n",
    "            data[5][4] = freq\n",
    "        if zone == 14:\n",
    "            data[1][1] = freq\n",
    "        if zone == 15:\n",
    "            data[2][1] = freq\n",
    "            data[3][1] = freq\n",
    "            data[4][1] = freq\n",
    "        if zone == 16:\n",
    "            data[5][1] = freq\n",
    "    return pandas.DataFrame.from_dict(data).sort_index(axis = 0, ascending=False)\n",
    "\n",
    "\n",
    "import seaborn  as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphs empirical distribution\n",
    "emp_df = get_x_y_zone_frequencies(emp_zone_counts)\n",
    "plt.title(\"Empirical Distribution Across Zones\")\n",
    "\n",
    "fig2 = sns.heatmap(emp_df, cmap =sns.light_palette(\"seagreen\", as_cmap=True), vmin=0, vmax=.15)\n",
    "\n",
    "plt.xlabel(\"X Zone\")\n",
    "plt.ylabel(\"Y Zone\")\n",
    "plt.savefig(\"empirical_dist.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphs samples from empirical pruned Gaussian distribution\n",
    "dist_df = get_x_y_zone_frequencies(dist_zone_counts)\n",
    "plt.title(\"Pruned Gaussian Distribution Across Zones\")\n",
    "fig2 = sns.heatmap(dist_df,cmap =sns.light_palette(\"seagreen\", as_cmap=True), vmin=0, vmax=.15)\n",
    "plt.xlabel(\"X Zone\")\n",
    "plt.ylabel(\"Y Zone\")\n",
    "plt.savefig(\"gaussian_dist.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphs samples from predicted pruned Gaussian distribution\n",
    "pred_df = get_x_y_zone_frequencies(pred_zone_counts)\n",
    "plt.title(\"Predicted Pruned Gaussian Distribution Across Zones\")\n",
    "fig2 = sns.heatmap(pred_df,cmap =sns.light_palette(\"seagreen\", as_cmap=True), vmin=0, vmax=.15)\n",
    "plt.xlabel(\"X Zone\")\n",
    "plt.ylabel(\"Y Zone\")\n",
    "plt.savefig(\"pred_gaussian_dist.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
